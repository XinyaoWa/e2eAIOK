+ DATA_PATH=/home/vmagent/app/LLM_datapre/data/
+ model_name=Llama-2-7b-chat-hf
+ model_name_or_path=/home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf
+ TRAIN_FILE=/home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/train.parquet
+ VALID_FILE=/home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/valid.parquet
+ prompt_file_viggo_textformat=/home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/prompt_mul
+ MODEL_SAVE_PATH=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models
+ model_save_path=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora
+ LOG_PATH=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/log
+ log_save_path=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/log/Llama-2-7b-chat-hf-lora-1epoch.log
+ log_save_path_valid=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/log/Llama-2-7b-chat-hf-lora-1epoch-valid.log
+ log_save_path_merge=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/log/Llama-2-7b-chat-hf-lora-1epoch-merge.log
+ mkdir -p /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/log /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models
+ WANDB_DISABLED=true
+ python -u example/instruction_tuning_pipeline/finetune_clm.py --model_name_or_path /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf --train_file /home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/train.parquet --prompt_type viggo_textformat --prompt_file_viggo_textformat /home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/prompt_mul --max_seq_length 1200 --per_device_train_batch_size 1 --gradient_accumulation_steps 8 --do_train --learning_rate 1e-4 --num_train_epochs 1 --logging_steps 100 --save_total_limit 1 --log_level info --save_strategy epoch --output_dir /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora --peft lora --trust_remote_code True --fp16 --load_in_8bit True
+ tee /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/log/Llama-2-7b-chat-hf-lora-1epoch.log
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
finetune_args is 
 FinetuneArguments(lora_rank=8, lora_alpha=16, lora_dropout=0.05, lora_target_modules=None, adapter_layers=30, adapter_len=10, num_virtual_tokens=10, ptun_hidden_size=1024, peft='lora', resume_peft='', delta=None, profile=False, train_on_inputs=True, habana=False, debugs=False, save_merged_model=False, merge_model_code_dir='', load_in_8bit=True, input_sentence='', output_length_limit=20, prompt_type='viggo_textformat', prompt_file_viggo_textformat='/home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/prompt_mul')
2024-02-23 16:03:42,217 - __main__ - WARNING - Process rank: 0, device: cuda:0
distributed training: True, 16-bits training: True
2024-02-23 16:03:42,217 - __main__ - INFO - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=8,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0001,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora/runs/Feb23_16-03-42_vsr134,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=100,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=1,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|configuration_utils.py:713] 2024-02-23 16:03:42,218 >> loading configuration file /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf/config.json
[INFO|configuration_utils.py:775] 2024-02-23 16:03:42,219 >> Model config LlamaConfig {
  "_name_or_path": "/home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.32.1",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:1850] 2024-02-23 16:03:42,220 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:1850] 2024-02-23 16:03:42,220 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:1850] 2024-02-23 16:03:42,220 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:1850] 2024-02-23 16:03:42,220 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:1850] 2024-02-23 16:03:42,220 >> loading file tokenizer_config.json
/opt/conda/lib/python3.10/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=None' instead.
  warnings.warn(
-----------------0-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.

##Output##

------------------
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

-----------------1-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
Dirt: Showdown is a sport racing game that was released in 2012. The game is available on PlayStation, Xbox, and PC, and it has an ESRB Rating of E 10+ (for Everyone 10 and Older). However, it is not yet available as a Steam, Linux, or Mac release.
Crysis is an action-adventure first person shooter developed by Crytek Frankfurt. It was originally released on PlayStation, Xbox, and PC and is available on Steam, but is not available for Linux or Mac.
Are you talking about the Heroes of Might and Magic III: The Restoration of Erathia that has been released on Linux though not available on Steam?

##Output##

------------------
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]
name[Crysis], developer[Crytek Frankfurt], genres[action-adventure, shooter], player_perspective[first person], platforms[PlayStation, Xbox, PC], available_on_steam[yes], has_linux_release[no], has_mac_release[no]
name[Heroes of Might and Magic III: The Restoration of Erathia], available_on_steam[no], has_linux_release[yes]

-----------------2-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
Dirt: Showdown is a driving/racing sport game released in 2012. It is rated E 10+, and is available on PlayStation, Xbox and PC, but not on Steam, Mac, or Linux.
Tetris from 1986 was played in the side view but didn't have multiplayer. It was an arcade, puzzle, strategy game by Spectrum HoloByte, Inc.
Tony Hawk's Pro Skater 3 is an average third person sports game that came out in 2001. It was developed by Neversoft Entertainment and rated T (for Teen).

##Output##

------------------
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]
name[Tetris], release_year[1986], developer[Spectrum HoloByte, Inc], genres[arcade, puzzle, strategy], player_perspective[side view], has_multiplayer[no]
name[Tony Hawk's Pro Skater 3], release_year[2001], developer[Neversoft Entertainment], esrb[T (for Teen)], rating[average], genres[sport], player_perspective[third person]

[INFO|modeling_utils.py:2422] 2024-02-23 16:03:43,821 >> The device_map was not initialized.Setting device_map to {'':torch.cuda.current_device()}.If you want to use the model for inference, please set device_map ='auto' 
[INFO|modeling_utils.py:2776] 2024-02-23 16:03:43,821 >> loading weights file /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf/model.safetensors.index.json
[INFO|modeling_utils.py:1191] 2024-02-23 16:03:43,822 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.
[INFO|configuration_utils.py:768] 2024-02-23 16:03:43,823 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "transformers_version": "4.32.1"
}

[INFO|modeling_utils.py:2891] 2024-02-23 16:03:44,022 >> Detected 8-bit loading: activating 8-bit loading for this model
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]
[INFO|modeling_utils.py:3551] 2024-02-23 16:03:50,647 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:3559] 2024-02-23 16:03:50,647 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:728] 2024-02-23 16:03:50,649 >> loading configuration file /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf/generation_config.json
[INFO|configuration_utils.py:768] 2024-02-23 16:03:50,650 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9,
  "transformers_version": "4.32.1"
}

2024-02-23 16:03:50,786 - __main__ - INFO - Using data collator of type DataCollatorForSeq2Seq
2024-02-23 16:03:58,245 - __main__ - INFO - ***original optimized model parameter***
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
[INFO|trainer.py:401] 2024-02-23 16:03:58,251 >> The model is quantized. To train this model you need to add additional modules inside the model such as adapters using `peft` library and freeze the model weights. Please check the examples in https://github.com/huggingface/peft for more details.
2024-02-23 16:03:58,252 - __main__ - INFO - *** Training ***
[INFO|trainer.py:750] 2024-02-23 16:03:58,445 >> The following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt_sources, prompt_targets. If prompt_sources, prompt_targets are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.
[INFO|trainer.py:1714] 2024-02-23 16:03:58,461 >> ***** Running training *****
[INFO|trainer.py:1715] 2024-02-23 16:03:58,461 >>   Num examples = 4,648
[INFO|trainer.py:1716] 2024-02-23 16:03:58,461 >>   Num Epochs = 1
[INFO|trainer.py:1717] 2024-02-23 16:03:58,461 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1720] 2024-02-23 16:03:58,461 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:1721] 2024-02-23 16:03:58,461 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:1722] 2024-02-23 16:03:58,461 >>   Total optimization steps = 581
[INFO|trainer.py:1723] 2024-02-23 16:03:58,462 >>   Number of trainable parameters = 4,194,304
  0%|          | 0/581 [00:00<?, ?it/s][WARNING|logging.py:290] 2024-02-23 16:03:58,467 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/581 [00:08<1:19:48,  8.26s/it]  0%|          | 2/581 [00:16<1:17:23,  8.02s/it]  1%|          | 3/581 [00:23<1:16:19,  7.92s/it]  1%|          | 4/581 [00:31<1:15:25,  7.84s/it]  1%|          | 5/581 [00:39<1:15:42,  7.89s/it]  1%|          | 6/581 [00:48<1:19:11,  8.26s/it]  1%|          | 7/581 [01:00<1:30:06,  9.42s/it]  1%|▏         | 8/581 [01:17<1:53:12, 11.85s/it]  2%|▏         | 9/581 [01:43<2:36:43, 16.44s/it]  2%|▏         | 10/581 [02:13<3:14:12, 20.41s/it]  2%|▏         | 11/581 [02:42<3:39:46, 23.13s/it]  2%|▏         | 12/581 [03:16<4:09:39, 26.33s/it]  2%|▏         | 13/581 [03:51<4:34:31, 29.00s/it]  2%|▏         | 14/581 [04:23<4:43:34, 30.01s/it]  3%|▎         | 15/581 [04:57<4:53:20, 31.10s/it]  3%|▎         | 16/581 [05:33<5:05:54, 32.49s/it]  3%|▎         | 17/581 [06:11<5:20:56, 34.14s/it]  3%|▎         | 18/581 [06:48<5:30:02, 35.17s/it]  3%|▎         | 19/581 [07:24<5:31:18, 35.37s/it]  3%|▎         | 20/581 [07:53<5:11:38, 33.33s/it]  4%|▎         | 21/581 [08:08<4:22:06, 28.08s/it]  4%|▍         | 22/581 [08:22<3:40:19, 23.65s/it]  4%|▍         | 23/581 [08:33<3:06:23, 20.04s/it]  4%|▍         | 24/581 [08:44<2:39:26, 17.18s/it]  4%|▍         | 25/581 [08:55<2:21:33, 15.28s/it]  4%|▍         | 26/581 [09:05<2:07:44, 13.81s/it]  5%|▍         | 27/581 [09:15<1:57:52, 12.77s/it]  5%|▍         | 28/581 [09:25<1:49:47, 11.91s/it]  5%|▍         | 29/581 [09:35<1:44:45, 11.39s/it]  5%|▌         | 30/581 [09:46<1:42:11, 11.13s/it]  5%|▌         | 31/581 [09:57<1:40:28, 10.96s/it]  6%|▌         | 32/581 [10:06<1:36:34, 10.55s/it]  6%|▌         | 33/581 [10:16<1:35:24, 10.45s/it]  6%|▌         | 34/581 [10:26<1:33:41, 10.28s/it]  6%|▌         | 35/581 [10:36<1:32:53, 10.21s/it]  6%|▌         | 36/581 [10:46<1:31:49, 10.11s/it]  6%|▋         | 37/581 [10:56<1:30:09,  9.94s/it]  7%|▋         | 38/581 [11:06<1:29:36,  9.90s/it]  7%|▋         | 39/581 [11:16<1:30:01,  9.97s/it]  7%|▋         | 40/581 [11:25<1:28:58,  9.87s/it]  7%|▋         | 41/581 [11:34<1:27:04,  9.68s/it]  7%|▋         | 42/581 [11:44<1:26:47,  9.66s/it]  7%|▋         | 43/581 [11:54<1:27:26,  9.75s/it]  8%|▊         | 44/581 [12:03<1:26:13,  9.63s/it]  8%|▊         | 45/581 [12:13<1:26:24,  9.67s/it]  8%|▊         | 46/581 [12:23<1:26:00,  9.65s/it]  8%|▊         | 47/581 [12:32<1:24:40,  9.51s/it]  8%|▊         | 48/581 [12:42<1:25:17,  9.60s/it]  8%|▊         | 49/581 [12:52<1:26:14,  9.73s/it]  9%|▊         | 50/581 [13:02<1:26:16,  9.75s/it]  9%|▉         | 51/581 [13:11<1:26:09,  9.75s/it]  9%|▉         | 52/581 [13:21<1:25:42,  9.72s/it]  9%|▉         | 53/581 [13:31<1:25:49,  9.75s/it]  9%|▉         | 54/581 [13:40<1:25:14,  9.70s/it]  9%|▉         | 55/581 [13:50<1:25:06,  9.71s/it] 10%|▉         | 56/581 [14:00<1:24:55,  9.71s/it] 10%|▉         | 57/581 [14:10<1:25:22,  9.77s/it] 10%|▉         | 58/581 [14:19<1:24:49,  9.73s/it] 10%|█         | 59/581 [14:29<1:23:56,  9.65s/it] 10%|█         | 60/581 [14:39<1:23:45,  9.65s/it] 10%|█         | 61/581 [14:48<1:22:34,  9.53s/it] 11%|█         | 62/581 [14:58<1:23:20,  9.63s/it] 11%|█         | 63/581 [15:07<1:23:12,  9.64s/it] 11%|█         | 64/581 [15:17<1:22:08,  9.53s/it] 11%|█         | 65/581 [15:26<1:21:55,  9.53s/it] 11%|█▏        | 66/581 [15:36<1:22:28,  9.61s/it] 12%|█▏        | 67/581 [15:45<1:22:01,  9.57s/it] 12%|█▏        | 68/581 [15:56<1:25:06,  9.95s/it] 12%|█▏        | 69/581 [16:12<1:39:08, 11.62s/it] 12%|█▏        | 70/581 [16:36<2:12:06, 15.51s/it] 12%|█▏        | 71/581 [17:06<2:47:37, 19.72s/it] 12%|█▏        | 72/581 [17:37<3:15:19, 23.03s/it] 13%|█▎        | 73/581 [18:09<3:38:24, 25.80s/it] 13%|█▎        | 74/581 [18:41<3:53:13, 27.60s/it] 13%|█▎        | 75/581 [19:14<4:06:58, 29.28s/it] 13%|█▎        | 76/581 [19:50<4:24:28, 31.42s/it] 13%|█▎        | 77/581 [20:24<4:30:51, 32.24s/it] 13%|█▎        | 78/581 [21:00<4:39:44, 33.37s/it] 14%|█▎        | 79/581 [21:37<4:48:02, 34.43s/it] 14%|█▍        | 80/581 [22:13<4:50:24, 34.78s/it] 14%|█▍        | 81/581 [22:47<4:48:04, 34.57s/it] 14%|█▍        | 82/581 [23:14<4:27:42, 32.19s/it] 14%|█▍        | 83/581 [23:28<3:41:51, 26.73s/it] 14%|█▍        | 84/581 [23:41<3:07:30, 22.64s/it] 15%|█▍        | 85/581 [23:52<2:39:32, 19.30s/it] 15%|█▍        | 86/581 [24:03<2:18:17, 16.76s/it] 15%|█▍        | 87/581 [24:14<2:03:57, 15.06s/it] 15%|█▌        | 88/581 [24:25<1:53:18, 13.79s/it] 15%|█▌        | 89/581 [24:35<1:44:32, 12.75s/it] 15%|█▌        | 90/581 [24:46<1:39:20, 12.14s/it] 16%|█▌        | 91/581 [24:57<1:34:58, 11.63s/it] 16%|█▌        | 92/581 [25:07<1:31:40, 11.25s/it] 16%|█▌        | 93/581 [25:17<1:28:37, 10.90s/it] 16%|█▌        | 94/581 [25:27<1:27:34, 10.79s/it] 16%|█▋        | 95/581 [25:38<1:26:15, 10.65s/it] 17%|█▋        | 96/581 [25:48<1:25:31, 10.58s/it] 17%|█▋        | 97/581 [25:58<1:24:29, 10.47s/it] 17%|█▋        | 98/581 [26:08<1:23:10, 10.33s/it] 17%|█▋        | 99/581 [26:18<1:20:54, 10.07s/it] 17%|█▋        | 100/581 [26:28<1:19:39,  9.94s/it]                                                   {'loss': 0.6233, 'learning_rate': 8.278829604130809e-05, 'epoch': 0.17}
 17%|█▋        | 100/581 [26:28<1:19:39,  9.94s/it] 17%|█▋        | 101/581 [26:37<1:17:57,  9.74s/it] 18%|█▊        | 102/581 [26:46<1:16:50,  9.63s/it] 18%|█▊        | 103/581 [26:56<1:16:33,  9.61s/it] 18%|█▊        | 104/581 [27:06<1:16:46,  9.66s/it] 18%|█▊        | 105/581 [27:15<1:16:48,  9.68s/it] 18%|█▊        | 106/581 [27:25<1:16:34,  9.67s/it] 18%|█▊        | 107/581 [27:35<1:17:01,  9.75s/it] 19%|█▊        | 108/581 [27:45<1:16:57,  9.76s/it] 19%|█▉        | 109/581 [27:54<1:16:09,  9.68s/it] 19%|█▉        | 110/581 [28:04<1:16:14,  9.71s/it] 19%|█▉        | 111/581 [28:13<1:15:43,  9.67s/it] 19%|█▉        | 112/581 [28:23<1:15:16,  9.63s/it] 19%|█▉        | 113/581 [28:33<1:15:39,  9.70s/it] 20%|█▉        | 114/581 [28:42<1:14:56,  9.63s/it] 20%|█▉        | 115/581 [28:52<1:15:08,  9.67s/it] 20%|█▉        | 116/581 [29:02<1:15:00,  9.68s/it] 20%|██        | 117/581 [29:12<1:15:50,  9.81s/it] 20%|██        | 118/581 [29:22<1:15:54,  9.84s/it] 20%|██        | 119/581 [29:31<1:15:11,  9.77s/it] 21%|██        | 120/581 [29:41<1:14:40,  9.72s/it] 21%|██        | 121/581 [29:51<1:14:30,  9.72s/it] 21%|██        | 122/581 [30:00<1:13:45,  9.64s/it] 21%|██        | 123/581 [30:10<1:14:19,  9.74s/it] 21%|██▏       | 124/581 [30:20<1:14:27,  9.78s/it] 22%|██▏       | 125/581 [30:30<1:14:34,  9.81s/it] 22%|██▏       | 126/581 [30:40<1:15:35,  9.97s/it] 22%|██▏       | 127/581 [30:53<1:22:32, 10.91s/it] 22%|██▏       | 128/581 [31:13<1:41:16, 13.41s/it] 22%|██▏       | 129/581 [31:39<2:10:52, 17.37s/it] 22%|██▏       | 130/581 [32:08<2:35:55, 20.74s/it] 23%|██▎       | 131/581 [32:39<2:59:32, 23.94s/it] 23%|██▎       | 132/581 [33:14<3:23:38, 27.21s/it] 23%|██▎       | 133/581 [33:48<3:38:39, 29.29s/it] 23%|██▎       | 134/581 [34:22<3:47:31, 30.54s/it] 23%|██▎       | 135/581 [34:58<4:00:23, 32.34s/it] 23%|██▎       | 136/581 [35:35<4:10:25, 33.76s/it] 24%|██▎       | 137/581 [36:10<4:11:59, 34.05s/it] 24%|██▍       | 138/581 [36:47<4:17:01, 34.81s/it] 24%|██▍       | 139/581 [37:22<4:18:24, 35.08s/it] 24%|██▍       | 140/581 [37:54<4:09:50, 33.99s/it] 24%|██▍       | 141/581 [38:10<3:29:59, 28.64s/it] 24%|██▍       | 142/581 [38:22<2:53:40, 23.74s/it] 25%|██▍       | 143/581 [38:34<2:26:56, 20.13s/it] 25%|██▍       | 144/581 [38:45<2:05:44, 17.26s/it] 25%|██▍       | 145/581 [38:55<1:50:17, 15.18s/it] 25%|██▌       | 146/581 [39:06<1:40:16, 13.83s/it] 25%|██▌       | 147/581 [39:16<1:32:54, 12.84s/it] 25%|██▌       | 148/581 [39:26<1:26:58, 12.05s/it] 26%|██▌       | 149/581 [39:36<1:22:13, 11.42s/it] 26%|██▌       | 150/581 [39:47<1:20:31, 11.21s/it] 26%|██▌       | 151/581 [39:58<1:19:39, 11.12s/it] 26%|██▌       | 152/581 [40:08<1:17:33, 10.85s/it] 26%|██▋       | 153/581 [40:18<1:16:16, 10.69s/it] 27%|██▋       | 154/581 [40:29<1:15:03, 10.55s/it] 27%|██▋       | 155/581 [40:39<1:14:24, 10.48s/it] 27%|██▋       | 156/581 [40:49<1:13:29, 10.38s/it] 27%|██▋       | 157/581 [40:59<1:13:06, 10.34s/it] 27%|██▋       | 158/581 [41:09<1:11:16, 10.11s/it] 27%|██▋       | 159/581 [41:18<1:10:04,  9.96s/it] 28%|██▊       | 160/581 [41:28<1:08:51,  9.81s/it] 28%|██▊       | 161/581 [41:38<1:09:00,  9.86s/it] 28%|██▊       | 162/581 [41:48<1:08:47,  9.85s/it] 28%|██▊       | 163/581 [41:57<1:08:19,  9.81s/it] 28%|██▊       | 164/581 [42:07<1:07:37,  9.73s/it] 28%|██▊       | 165/581 [42:17<1:08:16,  9.85s/it] 29%|██▊       | 166/581 [42:27<1:07:56,  9.82s/it] 29%|██▊       | 167/581 [42:37<1:07:24,  9.77s/it] 29%|██▉       | 168/581 [42:47<1:07:44,  9.84s/it] 29%|██▉       | 169/581 [42:56<1:07:46,  9.87s/it] 29%|██▉       | 170/581 [43:06<1:07:10,  9.81s/it] 29%|██▉       | 171/581 [43:15<1:06:00,  9.66s/it] 30%|██▉       | 172/581 [43:25<1:06:15,  9.72s/it] 30%|██▉       | 173/581 [43:35<1:05:41,  9.66s/it] 30%|██▉       | 174/581 [43:45<1:05:47,  9.70s/it] 30%|███       | 175/581 [43:55<1:06:05,  9.77s/it] 30%|███       | 176/581 [44:04<1:05:16,  9.67s/it] 30%|███       | 177/581 [44:14<1:05:24,  9.71s/it] 31%|███       | 178/581 [44:24<1:05:26,  9.74s/it] 31%|███       | 179/581 [44:33<1:05:17,  9.75s/it] 31%|███       | 180/581 [44:43<1:05:36,  9.82s/it] 31%|███       | 181/581 [44:53<1:05:54,  9.89s/it] 31%|███▏      | 182/581 [45:03<1:05:46,  9.89s/it] 31%|███▏      | 183/581 [45:13<1:05:14,  9.84s/it] 32%|███▏      | 184/581 [45:26<1:10:39, 10.68s/it] 32%|███▏      | 185/581 [45:44<1:25:02, 12.88s/it] 32%|███▏      | 186/581 [46:11<1:52:47, 17.13s/it] 32%|███▏      | 187/581 [46:41<2:19:10, 21.19s/it] 32%|███▏      | 188/581 [47:13<2:38:32, 24.20s/it] 33%|███▎      | 189/581 [47:46<2:56:27, 27.01s/it] 33%|███▎      | 190/581 [48:19<3:08:08, 28.87s/it] 33%|███▎      | 191/581 [48:55<3:20:24, 30.83s/it] 33%|███▎      | 192/581 [49:27<3:23:08, 31.33s/it] 33%|███▎      | 193/581 [50:05<3:35:07, 33.27s/it] 33%|███▎      | 194/581 [50:42<3:41:44, 34.38s/it] 34%|███▎      | 195/581 [51:19<3:45:21, 35.03s/it] 34%|███▎      | 196/581 [51:54<3:46:13, 35.26s/it] 34%|███▍      | 197/581 [52:22<3:30:53, 32.95s/it] 34%|███▍      | 198/581 [52:37<2:55:04, 27.43s/it] 34%|███▍      | 199/581 [52:50<2:27:09, 23.11s/it] 34%|███▍      | 200/581 [53:00<2:03:32, 19.45s/it]                                                   {'loss': 0.1687, 'learning_rate': 6.557659208261618e-05, 'epoch': 0.34}
 34%|███▍      | 200/581 [53:00<2:03:32, 19.45s/it] 35%|███▍      | 201/581 [53:11<1:47:00, 16.90s/it] 35%|███▍      | 202/581 [53:22<1:34:19, 14.93s/it] 35%|███▍      | 203/581 [53:32<1:26:09, 13.67s/it] 35%|███▌      | 204/581 [53:43<1:19:29, 12.65s/it] 35%|███▌      | 205/581 [53:53<1:14:19, 11.86s/it] 35%|███▌      | 206/581 [54:03<1:10:18, 11.25s/it] 36%|███▌      | 207/581 [54:13<1:08:25, 10.98s/it] 36%|███▌      | 208/581 [54:23<1:06:22, 10.68s/it] 36%|███▌      | 209/581 [54:33<1:05:41, 10.60s/it] 36%|███▌      | 210/581 [54:43<1:04:16, 10.40s/it] 36%|███▋      | 211/581 [54:53<1:03:37, 10.32s/it] 36%|███▋      | 212/581 [55:04<1:03:20, 10.30s/it] 37%|███▋      | 213/581 [55:14<1:02:31, 10.20s/it] 37%|███▋      | 214/581 [55:24<1:01:56, 10.13s/it] 37%|███▋      | 215/581 [55:34<1:01:44, 10.12s/it] 37%|███▋      | 216/581 [55:44<1:01:51, 10.17s/it] 37%|███▋      | 217/581 [55:53<1:00:07,  9.91s/it] 38%|███▊      | 218/581 [56:03<59:31,  9.84s/it]   38%|███▊      | 219/581 [56:13<59:20,  9.83s/it] 38%|███▊      | 220/581 [56:22<59:02,  9.81s/it] 38%|███▊      | 221/581 [56:32<58:32,  9.76s/it] 38%|███▊      | 222/581 [56:42<58:15,  9.74s/it] 38%|███▊      | 223/581 [56:52<58:22,  9.78s/it] 39%|███▊      | 224/581 [57:02<58:14,  9.79s/it] 39%|███▊      | 225/581 [57:11<58:03,  9.78s/it] 39%|███▉      | 226/581 [57:21<58:17,  9.85s/it] 39%|███▉      | 227/581 [57:31<57:40,  9.78s/it] 39%|███▉      | 228/581 [57:41<57:18,  9.74s/it] 39%|███▉      | 229/581 [57:50<56:49,  9.69s/it] 40%|███▉      | 230/581 [58:00<56:58,  9.74s/it] 40%|███▉      | 231/581 [58:10<56:43,  9.72s/it] 40%|███▉      | 232/581 [58:19<56:05,  9.64s/it] 40%|████      | 233/581 [58:29<56:29,  9.74s/it] 40%|████      | 234/581 [58:39<56:15,  9.73s/it] 40%|████      | 235/581 [58:49<56:11,  9.74s/it] 41%|████      | 236/581 [58:59<56:25,  9.81s/it] 41%|████      | 237/581 [59:08<56:25,  9.84s/it] 41%|████      | 238/581 [59:18<55:52,  9.77s/it] 41%|████      | 239/581 [59:28<55:41,  9.77s/it] 41%|████▏     | 240/581 [59:39<57:06, 10.05s/it] 41%|████▏     | 241/581 [59:53<1:03:58, 11.29s/it] 42%|████▏     | 242/581 [1:00:15<1:22:09, 14.54s/it] 42%|████▏     | 243/581 [1:00:43<1:44:17, 18.51s/it] 42%|████▏     | 244/581 [1:01:15<2:06:53, 22.59s/it] 42%|████▏     | 245/581 [1:01:45<2:19:36, 24.93s/it] 42%|████▏     | 246/581 [1:02:19<2:33:50, 27.55s/it] 43%|████▎     | 247/581 [1:02:54<2:46:30, 29.91s/it] 43%|████▎     | 248/581 [1:03:28<2:52:50, 31.14s/it] 43%|████▎     | 249/581 [1:04:05<3:00:52, 32.69s/it] 43%|████▎     | 250/581 [1:04:40<3:05:23, 33.61s/it] 43%|████▎     | 251/581 [1:05:17<3:10:38, 34.66s/it] 43%|████▎     | 252/581 [1:05:55<3:14:11, 35.42s/it] 44%|████▎     | 253/581 [1:06:10<2:41:30, 29.54s/it] 44%|████▎     | 254/581 [1:06:24<2:14:14, 24.63s/it] 44%|████▍     | 255/581 [1:06:36<1:53:27, 20.88s/it] 44%|████▍     | 256/581 [1:06:47<1:37:03, 17.92s/it] 44%|████▍     | 257/581 [1:06:57<1:25:01, 15.74s/it] 44%|████▍     | 258/581 [1:07:07<1:15:34, 14.04s/it] 45%|████▍     | 259/581 [1:07:18<1:09:03, 12.87s/it] 45%|████▍     | 260/581 [1:07:27<1:03:47, 11.92s/it] 45%|████▍     | 261/581 [1:07:38<1:01:38, 11.56s/it] 45%|████▌     | 262/581 [1:07:48<59:03, 11.11s/it]   45%|████▌     | 263/581 [1:07:58<57:05, 10.77s/it] 45%|████▌     | 264/581 [1:08:08<55:41, 10.54s/it] 46%|████▌     | 265/581 [1:08:17<53:46, 10.21s/it] 46%|████▌     | 266/581 [1:08:27<52:59, 10.09s/it] 46%|████▌     | 267/581 [1:08:37<52:47, 10.09s/it] 46%|████▌     | 268/581 [1:08:47<52:16, 10.02s/it] 46%|████▋     | 269/581 [1:08:57<52:03, 10.01s/it] 46%|████▋     | 270/581 [1:09:07<51:56, 10.02s/it] 47%|████▋     | 271/581 [1:09:17<51:41, 10.01s/it] 47%|████▋     | 272/581 [1:09:27<51:08,  9.93s/it] 47%|████▋     | 273/581 [1:09:37<50:53,  9.91s/it] 47%|████▋     | 274/581 [1:09:46<50:14,  9.82s/it] 47%|████▋     | 275/581 [1:09:56<49:26,  9.69s/it] 48%|████▊     | 276/581 [1:10:05<48:14,  9.49s/it] 48%|████▊     | 277/581 [1:10:15<48:40,  9.61s/it] 48%|████▊     | 278/581 [1:10:25<48:45,  9.65s/it] 48%|████▊     | 279/581 [1:10:34<48:47,  9.69s/it] 48%|████▊     | 280/581 [1:10:44<48:49,  9.73s/it] 48%|████▊     | 281/581 [1:10:54<48:11,  9.64s/it] 49%|████▊     | 282/581 [1:11:04<48:51,  9.81s/it] 49%|████▊     | 283/581 [1:11:14<49:00,  9.87s/it] 49%|████▉     | 284/581 [1:11:23<48:21,  9.77s/it] 49%|████▉     | 285/581 [1:11:33<48:23,  9.81s/it] 49%|████▉     | 286/581 [1:11:43<48:21,  9.84s/it] 49%|████▉     | 287/581 [1:11:53<48:36,  9.92s/it] 50%|████▉     | 288/581 [1:12:03<48:25,  9.92s/it] 50%|████▉     | 289/581 [1:12:13<47:55,  9.85s/it] 50%|████▉     | 290/581 [1:12:22<47:07,  9.72s/it] 50%|█████     | 291/581 [1:12:32<47:40,  9.86s/it] 50%|█████     | 292/581 [1:12:42<47:05,  9.78s/it] 50%|█████     | 293/581 [1:12:52<46:47,  9.75s/it] 51%|█████     | 294/581 [1:13:02<46:47,  9.78s/it] 51%|█████     | 295/581 [1:13:13<48:24, 10.16s/it] 51%|█████     | 296/581 [1:13:28<55:19, 11.65s/it] 51%|█████     | 297/581 [1:13:53<1:14:22, 15.71s/it] 51%|█████▏    | 298/581 [1:14:21<1:31:15, 19.35s/it] 51%|█████▏    | 299/581 [1:14:52<1:47:15, 22.82s/it] 52%|█████▏    | 300/581 [1:15:24<2:00:28, 25.72s/it]                                                     {'loss': 0.1442, 'learning_rate': 4.836488812392428e-05, 'epoch': 0.52}
 52%|█████▏    | 300/581 [1:15:24<2:00:28, 25.72s/it] 52%|█████▏    | 301/581 [1:15:56<2:09:08, 27.67s/it] 52%|█████▏    | 302/581 [1:16:31<2:18:32, 29.79s/it] 52%|█████▏    | 303/581 [1:17:05<2:23:18, 30.93s/it] 52%|█████▏    | 304/581 [1:17:40<2:29:26, 32.37s/it] 52%|█████▏    | 305/581 [1:18:14<2:30:14, 32.66s/it] 53%|█████▎    | 306/581 [1:18:50<2:34:06, 33.62s/it] 53%|█████▎    | 307/581 [1:19:19<2:27:47, 32.36s/it] 53%|█████▎    | 308/581 [1:19:34<2:03:21, 27.11s/it] 53%|█████▎    | 309/581 [1:19:46<1:43:01, 22.72s/it] 53%|█████▎    | 310/581 [1:19:57<1:26:33, 19.16s/it] 54%|█████▎    | 311/581 [1:20:08<1:14:41, 16.60s/it] 54%|█████▎    | 312/581 [1:20:18<1:06:13, 14.77s/it] 54%|█████▍    | 313/581 [1:20:29<59:52, 13.41s/it]   54%|█████▍    | 314/581 [1:20:39<55:36, 12.50s/it] 54%|█████▍    | 315/581 [1:20:49<52:23, 11.82s/it] 54%|█████▍    | 316/581 [1:20:59<49:17, 11.16s/it] 55%|█████▍    | 317/581 [1:21:09<48:12, 10.96s/it] 55%|█████▍    | 318/581 [1:21:19<46:56, 10.71s/it] 55%|█████▍    | 319/581 [1:21:30<45:58, 10.53s/it] 55%|█████▌    | 320/581 [1:21:39<44:55, 10.33s/it] 55%|█████▌    | 321/581 [1:21:49<44:07, 10.18s/it] 55%|█████▌    | 322/581 [1:21:59<43:23, 10.05s/it] 56%|█████▌    | 323/581 [1:22:09<42:46,  9.95s/it] 56%|█████▌    | 324/581 [1:22:19<42:48,  9.99s/it] 56%|█████▌    | 325/581 [1:22:29<42:35,  9.98s/it] 56%|█████▌    | 326/581 [1:22:39<42:28,  9.99s/it] 56%|█████▋    | 327/581 [1:22:49<42:17,  9.99s/it] 56%|█████▋    | 328/581 [1:22:59<41:55,  9.94s/it] 57%|█████▋    | 329/581 [1:23:09<42:00, 10.00s/it] 57%|█████▋    | 330/581 [1:23:19<41:52, 10.01s/it] 57%|█████▋    | 331/581 [1:23:29<41:26,  9.94s/it] 57%|█████▋    | 332/581 [1:23:39<41:19,  9.96s/it] 57%|█████▋    | 333/581 [1:23:48<40:58,  9.92s/it] 57%|█████▋    | 334/581 [1:23:58<40:48,  9.91s/it] 58%|█████▊    | 335/581 [1:24:07<39:43,  9.69s/it] 58%|█████▊    | 336/581 [1:24:18<40:02,  9.81s/it] 58%|█████▊    | 337/581 [1:24:27<39:56,  9.82s/it] 58%|█████▊    | 338/581 [1:24:37<39:49,  9.83s/it] 58%|█████▊    | 339/581 [1:24:47<39:30,  9.80s/it] 59%|█████▊    | 340/581 [1:24:56<38:55,  9.69s/it] 59%|█████▊    | 341/581 [1:25:06<38:46,  9.70s/it] 59%|█████▉    | 342/581 [1:25:16<38:36,  9.69s/it] 59%|█████▉    | 343/581 [1:25:25<38:20,  9.66s/it] 59%|█████▉    | 344/581 [1:25:35<38:05,  9.64s/it] 59%|█████▉    | 345/581 [1:25:45<37:47,  9.61s/it] 60%|█████▉    | 346/581 [1:25:54<37:43,  9.63s/it] 60%|█████▉    | 347/581 [1:26:04<38:10,  9.79s/it] 60%|█████▉    | 348/581 [1:26:15<39:28, 10.16s/it] 60%|██████    | 349/581 [1:26:31<45:58, 11.89s/it] 60%|██████    | 350/581 [1:26:55<59:28, 15.45s/it] 60%|██████    | 351/581 [1:27:24<1:14:23, 19.41s/it] 61%|██████    | 352/581 [1:27:54<1:26:28, 22.66s/it] 61%|██████    | 353/581 [1:28:26<1:36:51, 25.49s/it] 61%|██████    | 354/581 [1:28:59<1:44:32, 27.63s/it] 61%|██████    | 355/581 [1:29:32<1:51:03, 29.48s/it] 61%|██████▏   | 356/581 [1:30:06<1:54:50, 30.62s/it] 61%|██████▏   | 357/581 [1:30:40<1:58:47, 31.82s/it] 62%|██████▏   | 358/581 [1:31:17<2:03:29, 33.23s/it] 62%|██████▏   | 359/581 [1:31:52<2:05:00, 33.79s/it] 62%|██████▏   | 360/581 [1:32:24<2:01:58, 33.11s/it] 62%|██████▏   | 361/581 [1:32:39<1:41:59, 27.81s/it] 62%|██████▏   | 362/581 [1:32:52<1:25:27, 23.41s/it] 62%|██████▏   | 363/581 [1:33:03<1:11:50, 19.77s/it] 63%|██████▎   | 364/581 [1:33:15<1:02:18, 17.23s/it] 63%|██████▎   | 365/581 [1:33:26<55:21, 15.38s/it]   63%|██████▎   | 366/581 [1:33:36<49:57, 13.94s/it] 63%|██████▎   | 367/581 [1:33:47<45:53, 12.87s/it] 63%|██████▎   | 368/581 [1:33:58<43:30, 12.26s/it] 64%|██████▎   | 369/581 [1:34:08<41:07, 11.64s/it] 64%|██████▎   | 370/581 [1:34:18<39:40, 11.28s/it] 64%|██████▍   | 371/581 [1:34:28<38:05, 10.88s/it] 64%|██████▍   | 372/581 [1:34:38<37:08, 10.66s/it] 64%|██████▍   | 373/581 [1:34:49<36:44, 10.60s/it] 64%|██████▍   | 374/581 [1:34:59<36:12, 10.50s/it] 65%|██████▍   | 375/581 [1:35:09<35:33, 10.36s/it] 65%|██████▍   | 376/581 [1:35:19<34:47, 10.18s/it] 65%|██████▍   | 377/581 [1:35:29<34:29, 10.14s/it] 65%|██████▌   | 378/581 [1:35:39<34:05, 10.08s/it] 65%|██████▌   | 379/581 [1:35:49<33:46, 10.03s/it] 65%|██████▌   | 380/581 [1:35:59<33:36, 10.03s/it] 66%|██████▌   | 381/581 [1:36:09<33:13,  9.97s/it] 66%|██████▌   | 382/581 [1:36:18<32:48,  9.89s/it] 66%|██████▌   | 383/581 [1:36:28<32:13,  9.76s/it] 66%|██████▌   | 384/581 [1:36:37<31:35,  9.62s/it] 66%|██████▋   | 385/581 [1:36:47<31:28,  9.64s/it] 66%|██████▋   | 386/581 [1:36:56<31:12,  9.60s/it] 67%|██████▋   | 387/581 [1:37:06<31:10,  9.64s/it] 67%|██████▋   | 388/581 [1:37:15<30:52,  9.60s/it] 67%|██████▋   | 389/581 [1:37:25<30:49,  9.63s/it] 67%|██████▋   | 390/581 [1:37:35<30:43,  9.65s/it] 67%|██████▋   | 391/581 [1:37:44<30:32,  9.64s/it] 67%|██████▋   | 392/581 [1:37:54<30:30,  9.68s/it] 68%|██████▊   | 393/581 [1:38:04<30:27,  9.72s/it] 68%|██████▊   | 394/581 [1:38:14<30:28,  9.78s/it] 68%|██████▊   | 395/581 [1:38:24<30:07,  9.72s/it] 68%|██████▊   | 396/581 [1:38:33<29:53,  9.70s/it] 68%|██████▊   | 397/581 [1:38:43<30:02,  9.80s/it] 69%|██████▊   | 398/581 [1:38:53<29:34,  9.70s/it] 69%|██████▊   | 399/581 [1:39:02<29:29,  9.72s/it] 69%|██████▉   | 400/581 [1:39:13<29:48,  9.88s/it]                                                   {'loss': 0.1337, 'learning_rate': 3.115318416523236e-05, 'epoch': 0.69}
 69%|██████▉   | 400/581 [1:39:13<29:48,  9.88s/it] 69%|██████▉   | 401/581 [1:39:22<29:33,  9.85s/it] 69%|██████▉   | 402/581 [1:39:34<30:27, 10.21s/it] 69%|██████▉   | 403/581 [1:39:51<36:38, 12.35s/it] 70%|██████▉   | 404/581 [1:40:17<48:24, 16.41s/it] 70%|██████▉   | 405/581 [1:40:46<59:01, 20.12s/it] 70%|██████▉   | 406/581 [1:41:17<1:08:39, 23.54s/it] 70%|███████   | 407/581 [1:41:47<1:14:15, 25.61s/it] 70%|███████   | 408/581 [1:42:24<1:23:24, 28.93s/it] 70%|███████   | 409/581 [1:42:59<1:28:12, 30.77s/it] 71%|███████   | 410/581 [1:43:34<1:31:00, 31.93s/it] 71%|███████   | 411/581 [1:44:08<1:32:33, 32.67s/it] 71%|███████   | 412/581 [1:44:45<1:35:12, 33.80s/it] 71%|███████   | 413/581 [1:45:19<1:35:09, 33.99s/it] 71%|███████▏  | 414/581 [1:45:55<1:36:02, 34.50s/it] 71%|███████▏  | 415/581 [1:46:11<1:20:05, 28.95s/it] 72%|███████▏  | 416/581 [1:46:24<1:06:56, 24.34s/it] 72%|███████▏  | 417/581 [1:46:37<56:42, 20.75s/it]   72%|███████▏  | 418/581 [1:46:48<48:22, 17.81s/it] 72%|███████▏  | 419/581 [1:46:58<42:16, 15.66s/it] 72%|███████▏  | 420/581 [1:47:09<37:57, 14.15s/it] 72%|███████▏  | 421/581 [1:47:19<34:42, 13.01s/it] 73%|███████▎  | 422/581 [1:47:30<32:37, 12.31s/it] 73%|███████▎  | 423/581 [1:47:40<30:42, 11.66s/it] 73%|███████▎  | 424/581 [1:47:50<29:18, 11.20s/it] 73%|███████▎  | 425/581 [1:48:00<28:09, 10.83s/it] 73%|███████▎  | 426/581 [1:48:10<27:23, 10.60s/it] 73%|███████▎  | 427/581 [1:48:20<26:49, 10.45s/it] 74%|███████▎  | 428/581 [1:48:31<26:38, 10.45s/it] 74%|███████▍  | 429/581 [1:48:41<26:07, 10.31s/it] 74%|███████▍  | 430/581 [1:48:51<25:31, 10.14s/it] 74%|███████▍  | 431/581 [1:49:01<25:12, 10.09s/it] 74%|███████▍  | 432/581 [1:49:11<24:57, 10.05s/it] 75%|███████▍  | 433/581 [1:49:20<24:35,  9.97s/it] 75%|███████▍  | 434/581 [1:49:30<24:16,  9.91s/it] 75%|███████▍  | 435/581 [1:49:40<23:53,  9.82s/it] 75%|███████▌  | 436/581 [1:49:49<23:36,  9.77s/it] 75%|███████▌  | 437/581 [1:49:59<23:29,  9.79s/it] 75%|███████▌  | 438/581 [1:50:09<23:18,  9.78s/it] 76%|███████▌  | 439/581 [1:50:19<23:20,  9.87s/it] 76%|███████▌  | 440/581 [1:50:28<22:44,  9.68s/it] 76%|███████▌  | 441/581 [1:50:38<22:25,  9.61s/it] 76%|███████▌  | 442/581 [1:50:47<22:16,  9.62s/it] 76%|███████▌  | 443/581 [1:50:57<22:10,  9.64s/it] 76%|███████▋  | 444/581 [1:51:07<22:16,  9.75s/it] 77%|███████▋  | 445/581 [1:51:17<22:12,  9.80s/it] 77%|███████▋  | 446/581 [1:51:27<22:17,  9.91s/it] 77%|███████▋  | 447/581 [1:51:37<22:18,  9.99s/it] 77%|███████▋  | 448/581 [1:51:47<22:09, 10.00s/it] 77%|███████▋  | 449/581 [1:51:57<21:48,  9.91s/it] 77%|███████▋  | 450/581 [1:52:07<21:43,  9.95s/it] 78%|███████▊  | 451/581 [1:52:17<21:31,  9.93s/it] 78%|███████▊  | 452/581 [1:52:27<21:21,  9.94s/it] 78%|███████▊  | 453/581 [1:52:37<21:05,  9.89s/it] 78%|███████▊  | 454/581 [1:52:46<20:34,  9.72s/it] 78%|███████▊  | 455/581 [1:52:56<20:16,  9.66s/it] 78%|███████▊  | 456/581 [1:53:06<20:48,  9.99s/it] 79%|███████▊  | 457/581 [1:53:20<23:11, 11.22s/it] 79%|███████▉  | 458/581 [1:53:44<30:34, 14.91s/it] 79%|███████▉  | 459/581 [1:54:12<38:11, 18.78s/it] 79%|███████▉  | 460/581 [1:54:41<44:21, 21.99s/it] 79%|███████▉  | 461/581 [1:55:13<49:43, 24.86s/it] 80%|███████▉  | 462/581 [1:55:46<54:18, 27.38s/it] 80%|███████▉  | 463/581 [1:56:20<57:55, 29.45s/it] 80%|███████▉  | 464/581 [1:56:55<1:00:20, 30.95s/it] 80%|████████  | 465/581 [1:57:29<1:01:46, 31.95s/it] 80%|████████  | 466/581 [1:58:07<1:04:37, 33.71s/it] 80%|████████  | 467/581 [1:58:43<1:05:18, 34.37s/it] 81%|████████  | 468/581 [1:59:19<1:05:30, 34.79s/it] 81%|████████  | 469/581 [1:59:38<56:11, 30.10s/it]   81%|████████  | 470/581 [1:59:51<46:11, 24.97s/it] 81%|████████  | 471/581 [2:00:02<38:31, 21.01s/it] 81%|████████  | 472/581 [2:00:14<32:47, 18.05s/it] 81%|████████▏ | 473/581 [2:00:25<28:56, 16.08s/it] 82%|████████▏ | 474/581 [2:00:36<25:48, 14.47s/it] 82%|████████▏ | 475/581 [2:00:46<23:28, 13.29s/it] 82%|████████▏ | 476/581 [2:00:57<21:53, 12.51s/it] 82%|████████▏ | 477/581 [2:01:07<20:26, 11.79s/it] 82%|████████▏ | 478/581 [2:01:17<19:26, 11.33s/it] 82%|████████▏ | 479/581 [2:01:28<18:39, 10.97s/it] 83%|████████▎ | 480/581 [2:01:38<18:14, 10.83s/it] 83%|████████▎ | 481/581 [2:01:48<17:46, 10.67s/it] 83%|████████▎ | 482/581 [2:01:58<17:16, 10.47s/it] 83%|████████▎ | 483/581 [2:02:08<16:50, 10.31s/it] 83%|████████▎ | 484/581 [2:02:18<16:33, 10.24s/it] 83%|████████▎ | 485/581 [2:02:28<16:10, 10.11s/it] 84%|████████▎ | 486/581 [2:02:39<16:10, 10.21s/it] 84%|████████▍ | 487/581 [2:02:49<15:54, 10.15s/it] 84%|████████▍ | 488/581 [2:02:58<15:31, 10.02s/it] 84%|████████▍ | 489/581 [2:03:08<15:09,  9.89s/it] 84%|████████▍ | 490/581 [2:03:17<14:49,  9.78s/it] 85%|████████▍ | 491/581 [2:03:27<14:44,  9.83s/it] 85%|████████▍ | 492/581 [2:03:37<14:40,  9.89s/it] 85%|████████▍ | 493/581 [2:03:47<14:18,  9.76s/it] 85%|████████▌ | 494/581 [2:03:57<14:06,  9.73s/it] 85%|████████▌ | 495/581 [2:04:07<14:08,  9.87s/it] 85%|████████▌ | 496/581 [2:04:16<13:42,  9.68s/it] 86%|████████▌ | 497/581 [2:04:26<13:38,  9.74s/it] 86%|████████▌ | 498/581 [2:04:36<13:32,  9.79s/it] 86%|████████▌ | 499/581 [2:04:45<13:16,  9.71s/it] 86%|████████▌ | 500/581 [2:04:55<13:11,  9.77s/it]                                                   {'loss': 0.1272, 'learning_rate': 1.3941480206540447e-05, 'epoch': 0.86}
 86%|████████▌ | 500/581 [2:04:55<13:11,  9.77s/it] 86%|████████▌ | 501/581 [2:05:05<12:54,  9.68s/it] 86%|████████▋ | 502/581 [2:05:14<12:40,  9.63s/it] 87%|████████▋ | 503/581 [2:05:24<12:42,  9.77s/it] 87%|████████▋ | 504/581 [2:05:34<12:29,  9.74s/it] 87%|████████▋ | 505/581 [2:05:44<12:22,  9.77s/it] 87%|████████▋ | 506/581 [2:05:54<12:14,  9.79s/it] 87%|████████▋ | 507/581 [2:06:04<12:09,  9.86s/it] 87%|████████▋ | 508/581 [2:06:13<11:52,  9.75s/it] 88%|████████▊ | 509/581 [2:06:23<11:37,  9.69s/it] 88%|████████▊ | 510/581 [2:06:33<11:41,  9.88s/it] 88%|████████▊ | 511/581 [2:06:47<12:49, 11.00s/it] 88%|████████▊ | 512/581 [2:07:06<15:43, 13.67s/it] 88%|████████▊ | 513/581 [2:07:33<19:59, 17.65s/it] 88%|████████▊ | 514/581 [2:08:05<24:14, 21.70s/it] 89%|████████▊ | 515/581 [2:08:34<26:16, 23.89s/it] 89%|████████▉ | 516/581 [2:09:07<28:55, 26.70s/it] 89%|████████▉ | 517/581 [2:09:43<31:27, 29.49s/it] 89%|████████▉ | 518/581 [2:10:17<32:22, 30.84s/it] 89%|████████▉ | 519/581 [2:10:51<32:56, 31.88s/it] 90%|████████▉ | 520/581 [2:11:26<33:12, 32.66s/it] 90%|████████▉ | 521/581 [2:12:02<33:44, 33.73s/it] 90%|████████▉ | 522/581 [2:12:38<33:49, 34.41s/it] 90%|█████████ | 523/581 [2:12:56<28:32, 29.52s/it] 90%|█████████ | 524/581 [2:13:10<23:45, 25.00s/it] 90%|█████████ | 525/581 [2:13:23<19:43, 21.13s/it] 91%|█████████ | 526/581 [2:13:33<16:34, 18.08s/it] 91%|█████████ | 527/581 [2:13:44<14:18, 15.90s/it] 91%|█████████ | 528/581 [2:13:55<12:46, 14.45s/it] 91%|█████████ | 529/581 [2:14:06<11:30, 13.28s/it] 91%|█████████ | 530/581 [2:14:16<10:33, 12.41s/it] 91%|█████████▏| 531/581 [2:14:27<09:49, 11.80s/it] 92%|█████████▏| 532/581 [2:14:37<09:12, 11.27s/it] 92%|█████████▏| 533/581 [2:14:47<08:45, 10.95s/it] 92%|█████████▏| 534/581 [2:14:57<08:19, 10.63s/it] 92%|█████████▏| 535/581 [2:15:07<07:57, 10.38s/it] 92%|█████████▏| 536/581 [2:15:16<07:40, 10.22s/it] 92%|█████████▏| 537/581 [2:15:26<07:24, 10.10s/it] 93%|█████████▎| 538/581 [2:15:36<07:13, 10.09s/it] 93%|█████████▎| 539/581 [2:15:46<07:03, 10.08s/it] 93%|█████████▎| 540/581 [2:15:56<06:48,  9.96s/it] 93%|█████████▎| 541/581 [2:16:06<06:38,  9.95s/it] 93%|█████████▎| 542/581 [2:16:16<06:30, 10.01s/it] 93%|█████████▎| 543/581 [2:16:26<06:15,  9.88s/it] 94%|█████████▎| 544/581 [2:16:36<06:06,  9.89s/it] 94%|█████████▍| 545/581 [2:16:45<05:51,  9.77s/it] 94%|█████████▍| 546/581 [2:16:54<05:34,  9.57s/it] 94%|█████████▍| 547/581 [2:17:04<05:27,  9.62s/it] 94%|█████████▍| 548/581 [2:17:14<05:21,  9.75s/it] 94%|█████████▍| 549/581 [2:17:24<05:09,  9.69s/it] 95%|█████████▍| 550/581 [2:17:33<04:55,  9.54s/it] 95%|█████████▍| 551/581 [2:17:43<04:50,  9.68s/it] 95%|█████████▌| 552/581 [2:17:52<04:40,  9.67s/it] 95%|█████████▌| 553/581 [2:18:02<04:27,  9.55s/it] 95%|█████████▌| 554/581 [2:18:12<04:21,  9.69s/it] 96%|█████████▌| 555/581 [2:18:21<04:11,  9.67s/it] 96%|█████████▌| 556/581 [2:18:31<03:59,  9.58s/it] 96%|█████████▌| 557/581 [2:18:41<03:52,  9.68s/it] 96%|█████████▌| 558/581 [2:18:50<03:42,  9.67s/it] 96%|█████████▌| 559/581 [2:19:00<03:32,  9.65s/it] 96%|█████████▋| 560/581 [2:19:10<03:23,  9.70s/it] 97%|█████████▋| 561/581 [2:19:19<03:13,  9.66s/it] 97%|█████████▋| 562/581 [2:19:29<03:04,  9.72s/it] 97%|█████████▋| 563/581 [2:19:39<02:53,  9.66s/it] 97%|█████████▋| 564/581 [2:19:49<02:47,  9.83s/it] 97%|█████████▋| 565/581 [2:20:01<02:50, 10.68s/it] 97%|█████████▋| 566/581 [2:20:21<03:18, 13.24s/it] 98%|█████████▊| 567/581 [2:20:47<03:59, 17.12s/it] 98%|█████████▊| 568/581 [2:21:16<04:28, 20.67s/it] 98%|█████████▊| 569/581 [2:21:48<04:49, 24.14s/it] 98%|█████████▊| 570/581 [2:22:21<04:53, 26.67s/it] 98%|█████████▊| 571/581 [2:22:53<04:42, 28.26s/it] 98%|█████████▊| 572/581 [2:23:25<04:24, 29.44s/it] 99%|█████████▊| 573/581 [2:24:00<04:10, 31.30s/it] 99%|█████████▉| 574/581 [2:24:36<03:47, 32.44s/it] 99%|█████████▉| 575/581 [2:25:12<03:21, 33.57s/it] 99%|█████████▉| 576/581 [2:25:49<02:53, 34.66s/it] 99%|█████████▉| 577/581 [2:26:21<02:15, 33.94s/it] 99%|█████████▉| 578/581 [2:26:37<01:25, 28.59s/it]100%|█████████▉| 579/581 [2:26:50<00:47, 23.92s/it]100%|█████████▉| 580/581 [2:27:02<00:20, 20.31s/it]100%|██████████| 581/581 [2:27:13<00:00, 17.54s/it][INFO|trainer.py:2845] 2024-02-23 18:31:12,254 >> Saving model checkpoint to /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora/checkpoint-581
[INFO|tokenization_utils_base.py:2235] 2024-02-23 18:31:12,287 >> tokenizer config file saved in /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora/checkpoint-581/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2024-02-23 18:31:12,287 >> Special tokens file saved in /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora/checkpoint-581/special_tokens_map.json
[INFO|trainer.py:1962] 2024-02-23 18:31:12,399 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   {'train_runtime': 8833.9365, 'train_samples_per_second': 0.526, 'train_steps_per_second': 0.066, 'train_loss': 0.22362466933600053, 'epoch': 1.0}
100%|██████████| 581/581 [2:27:13<00:00, 17.54s/it]100%|██████████| 581/581 [2:27:13<00:00, 15.20s/it]
+ WANDB_DISABLED=true
+ python -u example/instruction_tuning_pipeline/finetune_clm.py --model_name_or_path /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf --train_file /home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/train.parquet --validation_file /home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/valid.parquet --prompt_type viggo_textformat --prompt_file_viggo_textformat /home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/prompt_mul --max_seq_length 1200 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --logging_steps 100 --save_total_limit 1 --log_level info --output_dir /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora --peft lora --trust_remote_code True --load_in_8bit False --resume_peft /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora
+ tee /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/log/Llama-2-7b-chat-hf-lora-1epoch-valid.log
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
finetune_args is 
 FinetuneArguments(lora_rank=8, lora_alpha=16, lora_dropout=0.05, lora_target_modules=None, adapter_layers=30, adapter_len=10, num_virtual_tokens=10, ptun_hidden_size=1024, peft='lora', resume_peft='/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora', delta=None, profile=False, train_on_inputs=True, habana=False, debugs=False, save_merged_model=False, merge_model_code_dir='', load_in_8bit=False, input_sentence='', output_length_limit=20, prompt_type='viggo_textformat', prompt_file_viggo_textformat='/home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/prompt_mul')
2024-02-23 18:31:17,215 - __main__ - WARNING - Process rank: 0, device: cuda:0
distributed training: True, 16-bits training: False
2024-02-23 18:31:17,215 - __main__ - INFO - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora/runs/Feb23_18-31-17_vsr134,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=100,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=1,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|configuration_utils.py:713] 2024-02-23 18:31:17,216 >> loading configuration file /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf/config.json
[INFO|configuration_utils.py:775] 2024-02-23 18:31:17,217 >> Model config LlamaConfig {
  "_name_or_path": "/home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.32.1",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:1850] 2024-02-23 18:31:17,218 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:1850] 2024-02-23 18:31:17,218 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:1850] 2024-02-23 18:31:17,218 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:1850] 2024-02-23 18:31:17,218 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:1850] 2024-02-23 18:31:17,218 >> loading file tokenizer_config.json
/opt/conda/lib/python3.10/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=None' instead.
  warnings.warn(
-----------------0-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.

##Output##

------------------
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

-----------------1-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
Dirt: Showdown is a sport racing game that was released in 2012. The game is available on PlayStation, Xbox, and PC, and it has an ESRB Rating of E 10+ (for Everyone 10 and Older). However, it is not yet available as a Steam, Linux, or Mac release.
Crysis is an action-adventure first person shooter developed by Crytek Frankfurt. It was originally released on PlayStation, Xbox, and PC and is available on Steam, but is not available for Linux or Mac.
Are you talking about the Heroes of Might and Magic III: The Restoration of Erathia that has been released on Linux though not available on Steam?

##Output##

------------------
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]
name[Crysis], developer[Crytek Frankfurt], genres[action-adventure, shooter], player_perspective[first person], platforms[PlayStation, Xbox, PC], available_on_steam[yes], has_linux_release[no], has_mac_release[no]
name[Heroes of Might and Magic III: The Restoration of Erathia], available_on_steam[no], has_linux_release[yes]

-----------------2-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
Dirt: Showdown is a driving/racing sport game released in 2012. It is rated E 10+, and is available on PlayStation, Xbox and PC, but not on Steam, Mac, or Linux.
Tetris from 1986 was played in the side view but didn't have multiplayer. It was an arcade, puzzle, strategy game by Spectrum HoloByte, Inc.
Tony Hawk's Pro Skater 3 is an average third person sports game that came out in 2001. It was developed by Neversoft Entertainment and rated T (for Teen).

##Output##

------------------
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]
name[Tetris], release_year[1986], developer[Spectrum HoloByte, Inc], genres[arcade, puzzle, strategy], player_perspective[side view], has_multiplayer[no]
name[Tony Hawk's Pro Skater 3], release_year[2001], developer[Neversoft Entertainment], esrb[T (for Teen)], rating[average], genres[sport], player_perspective[third person]

-----------------0-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
SpellForce 3 is a pretty bad game. The developer Grimlore Games is clearly a bunch of no-talent hacks, and 2017 was a terrible year for games anyway.

##Output##

------------------
name[SpellForce 3], release_year[2017], developer[Grimlore Games], rating[poor]

-----------------1-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
I wanted to like Grimlore Games' 2017 entry, but in SpellForce 3 they just didn't get anything right.
Do you like EA Digital Illusions CE's games with multiplayer in them like Mirror's Edge Catalyst?
You recently said you liked Commandos: Behind Enemy Lines, which is on Steam. Do you normally like playing PC games like this?
Nightshade is a text adventure game by Red Entertainment Corporation that came out in 2017. This game doesn't have multiplayer.
Metro 2033 is an role-playing action shooter game that was released in 2010. It can be played on Xbox and PC and is on Steam. It hasn't been released on Linux or Mac. It can only be played as a single-player.

##Output##

------------------
name[SpellForce 3], release_year[2017], developer[Grimlore Games], rating[poor]
name[Mirror's Edge Catalyst], developer[EA Digital Illusions CE], has_multiplayer[yes]
name[Commandos: Behind Enemy Lines], rating[good], platforms[PC], available_on_steam[yes]
name[Nightshade], release_year[2017], developer[Red Entertainment Corporation], genres[text adventure], has_multiplayer[no]
name[Metro 2033], release_year[2010], genres[action, role-playing, shooter], has_multiplayer[no], platforms[Xbox, PC], available_on_steam[yes], has_linux_release[no], has_mac_release[no]

-----------------2-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
I think SpellForce 3 is really, really bad. It's made by Grimlore Games and their games are always terrible, but it also came out in 2017, which was an especially bad year for them.
FIFA 12 is so-so in my opinion. EA Canada is an okay developer, but they don't really know how to bring out the full potential of the Xbox.
Speaking of multiplayer sports games, have you heard of Tony Hawk's Pro Skater 3?

##Output##

------------------
name[SpellForce 3], release_year[2017], developer[Grimlore Games], rating[poor]
name[FIFA 12], developer[EA Canada], rating[average], platforms[Xbox]
name[Tony Hawk's Pro Skater 3], genres[sport], has_multiplayer[yes]

[INFO|modeling_utils.py:2776] 2024-02-23 18:31:18,935 >> loading weights file /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf/model.safetensors.index.json
[INFO|configuration_utils.py:768] 2024-02-23 18:31:18,936 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "transformers_version": "4.32.1"
}

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
[INFO|modeling_utils.py:3551] 2024-02-23 18:31:22,069 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:3559] 2024-02-23 18:31:22,070 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:728] 2024-02-23 18:31:22,078 >> loading configuration file /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf/generation_config.json
[INFO|configuration_utils.py:768] 2024-02-23 18:31:22,079 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9,
  "transformers_version": "4.32.1"
}

Map:   0%|          | 0/714 [00:00<?, ? examples/s]Map: 100%|██████████| 714/714 [00:00<00:00, 991.94 examples/s]Map: 100%|██████████| 714/714 [00:00<00:00, 975.83 examples/s]
2024-02-23 18:31:22,901 - __main__ - INFO - Using data collator of type DataCollatorForSeq2Seq
2024-02-23 18:31:37,055 - __main__ - INFO - ***original optimized model parameter***
trainable params: 0 || all params: 6,742,609,920 || trainable%: 0.0
2024-02-23 18:31:55,511 - __main__ - INFO - *** Evaluate ***
[INFO|trainer.py:750] 2024-02-23 18:31:55,512 >> The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt_sources, prompt_targets. If prompt_sources, prompt_targets are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.
[INFO|trainer.py:3119] 2024-02-23 18:31:55,525 >> ***** Running Evaluation *****
[INFO|trainer.py:3121] 2024-02-23 18:31:55,525 >>   Num examples = 714
[INFO|trainer.py:3124] 2024-02-23 18:31:55,525 >>   Batch size = 1
[WARNING|logging.py:290] 2024-02-23 18:31:55,530 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 0/714 [00:00<?, ?it/s]  0%|          | 2/714 [00:01<07:28,  1.59it/s]  0%|          | 3/714 [00:02<11:15,  1.05it/s]  1%|          | 4/714 [00:04<13:05,  1.11s/it]  1%|          | 5/714 [00:05<14:19,  1.21s/it]  1%|          | 6/714 [00:06<14:50,  1.26s/it]  1%|          | 7/714 [00:08<14:52,  1.26s/it]  1%|          | 8/714 [00:09<14:37,  1.24s/it]  1%|▏         | 9/714 [00:10<14:18,  1.22s/it]  1%|▏         | 10/714 [00:11<13:56,  1.19s/it]  2%|▏         | 11/714 [00:12<13:36,  1.16s/it]  2%|▏         | 12/714 [00:13<13:49,  1.18s/it]  2%|▏         | 13/714 [00:15<14:25,  1.23s/it]  2%|▏         | 14/714 [00:16<14:09,  1.21s/it]  2%|▏         | 15/714 [00:17<14:21,  1.23s/it]  2%|▏         | 16/714 [00:19<14:51,  1.28s/it]  2%|▏         | 17/714 [00:20<14:48,  1.28s/it]  3%|▎         | 18/714 [00:21<14:58,  1.29s/it]  3%|▎         | 19/714 [00:23<15:30,  1.34s/it]  3%|▎         | 20/714 [00:24<15:47,  1.37s/it]  3%|▎         | 21/714 [00:25<15:36,  1.35s/it]  3%|▎         | 22/714 [00:27<15:40,  1.36s/it]  3%|▎         | 23/714 [00:28<16:14,  1.41s/it]  3%|▎         | 24/714 [00:30<16:36,  1.44s/it]  4%|▎         | 25/714 [00:31<16:41,  1.45s/it]  4%|▎         | 26/714 [00:33<17:11,  1.50s/it]  4%|▍         | 27/714 [00:34<16:59,  1.48s/it]  4%|▍         | 28/714 [00:36<16:40,  1.46s/it]  4%|▍         | 29/714 [00:37<17:17,  1.51s/it]  4%|▍         | 30/714 [00:39<17:28,  1.53s/it]  4%|▍         | 31/714 [00:40<17:12,  1.51s/it]  4%|▍         | 32/714 [00:42<17:45,  1.56s/it]  5%|▍         | 33/714 [00:44<18:17,  1.61s/it]  5%|▍         | 34/714 [00:45<18:30,  1.63s/it]  5%|▍         | 35/714 [00:47<18:46,  1.66s/it]  5%|▌         | 36/714 [00:49<19:06,  1.69s/it]  5%|▌         | 37/714 [00:51<19:01,  1.69s/it]  5%|▌         | 38/714 [00:52<18:56,  1.68s/it]  5%|▌         | 39/714 [00:54<19:04,  1.70s/it]  6%|▌         | 40/714 [00:56<19:20,  1.72s/it]  6%|▌         | 41/714 [00:57<18:50,  1.68s/it]  6%|▌         | 42/714 [00:59<18:27,  1.65s/it]  6%|▌         | 43/714 [01:01<18:44,  1.68s/it]  6%|▌         | 44/714 [01:03<19:05,  1.71s/it]  6%|▋         | 45/714 [01:04<19:42,  1.77s/it]  6%|▋         | 46/714 [01:06<19:54,  1.79s/it]  7%|▋         | 47/714 [01:08<19:23,  1.74s/it]  7%|▋         | 48/714 [01:09<18:53,  1.70s/it]  7%|▋         | 49/714 [01:11<18:56,  1.71s/it]  7%|▋         | 50/714 [01:13<18:35,  1.68s/it]  7%|▋         | 51/714 [01:14<18:05,  1.64s/it]  7%|▋         | 52/714 [01:16<18:33,  1.68s/it]  7%|▋         | 53/714 [01:18<19:04,  1.73s/it]  8%|▊         | 54/714 [01:20<18:58,  1.73s/it]  8%|▊         | 55/714 [01:21<18:59,  1.73s/it]  8%|▊         | 56/714 [01:23<18:35,  1.70s/it]  8%|▊         | 57/714 [01:25<18:51,  1.72s/it]  8%|▊         | 58/714 [01:27<19:37,  1.80s/it]  8%|▊         | 59/714 [01:29<19:31,  1.79s/it]  8%|▊         | 60/714 [01:30<19:14,  1.77s/it]  9%|▊         | 61/714 [01:32<19:02,  1.75s/it]  9%|▊         | 62/714 [01:34<19:06,  1.76s/it]  9%|▉         | 63/714 [01:36<19:40,  1.81s/it]  9%|▉         | 64/714 [01:37<19:21,  1.79s/it]  9%|▉         | 65/714 [01:39<19:20,  1.79s/it]  9%|▉         | 66/714 [01:41<19:31,  1.81s/it]  9%|▉         | 67/714 [01:43<18:57,  1.76s/it] 10%|▉         | 68/714 [01:44<18:36,  1.73s/it] 10%|▉         | 69/714 [01:46<18:15,  1.70s/it] 10%|▉         | 70/714 [01:48<17:58,  1.67s/it] 10%|▉         | 71/714 [01:49<18:17,  1.71s/it] 10%|█         | 72/714 [01:51<19:17,  1.80s/it] 10%|█         | 73/714 [01:53<19:55,  1.87s/it] 10%|█         | 74/714 [01:55<19:39,  1.84s/it] 11%|█         | 75/714 [01:57<19:13,  1.80s/it] 11%|█         | 76/714 [01:59<19:49,  1.86s/it] 11%|█         | 77/714 [02:01<19:46,  1.86s/it] 11%|█         | 78/714 [02:03<19:32,  1.84s/it] 11%|█         | 79/714 [02:05<19:49,  1.87s/it] 11%|█         | 80/714 [02:06<19:39,  1.86s/it] 11%|█▏        | 81/714 [02:08<19:15,  1.83s/it] 11%|█▏        | 82/714 [02:10<18:35,  1.77s/it] 12%|█▏        | 83/714 [02:12<18:40,  1.78s/it] 12%|█▏        | 84/714 [02:14<19:06,  1.82s/it] 12%|█▏        | 85/714 [02:15<19:04,  1.82s/it] 12%|█▏        | 86/714 [02:17<19:22,  1.85s/it] 12%|█▏        | 87/714 [02:19<19:52,  1.90s/it] 12%|█▏        | 88/714 [02:21<19:39,  1.88s/it] 12%|█▏        | 89/714 [02:23<19:17,  1.85s/it] 13%|█▎        | 90/714 [02:25<19:14,  1.85s/it] 13%|█▎        | 91/714 [02:26<18:47,  1.81s/it] 13%|█▎        | 92/714 [02:28<18:32,  1.79s/it] 13%|█▎        | 93/714 [02:30<17:58,  1.74s/it] 13%|█▎        | 94/714 [02:31<17:46,  1.72s/it] 13%|█▎        | 95/714 [02:33<17:52,  1.73s/it] 13%|█▎        | 96/714 [02:35<17:41,  1.72s/it] 14%|█▎        | 97/714 [02:36<17:09,  1.67s/it] 14%|█▎        | 98/714 [02:38<17:05,  1.66s/it] 14%|█▍        | 99/714 [02:40<17:22,  1.70s/it] 14%|█▍        | 100/714 [02:42<17:33,  1.72s/it] 14%|█▍        | 101/714 [02:43<17:26,  1.71s/it] 14%|█▍        | 102/714 [02:45<16:56,  1.66s/it] 14%|█▍        | 103/714 [02:47<16:46,  1.65s/it] 15%|█▍        | 104/714 [02:48<16:57,  1.67s/it] 15%|█▍        | 105/714 [02:50<17:20,  1.71s/it] 15%|█▍        | 106/714 [02:52<17:47,  1.76s/it] 15%|█▍        | 107/714 [02:54<17:46,  1.76s/it] 15%|█▌        | 108/714 [02:55<17:23,  1.72s/it] 15%|█▌        | 109/714 [02:57<17:02,  1.69s/it] 15%|█▌        | 110/714 [02:59<17:04,  1.70s/it] 16%|█▌        | 111/714 [03:00<17:21,  1.73s/it] 16%|█▌        | 112/714 [03:02<17:54,  1.78s/it] 16%|█▌        | 113/714 [03:04<17:46,  1.77s/it] 16%|█▌        | 114/714 [03:06<17:02,  1.70s/it] 16%|█▌        | 115/714 [03:07<16:45,  1.68s/it] 16%|█▌        | 116/714 [03:09<16:52,  1.69s/it] 16%|█▋        | 117/714 [03:11<16:47,  1.69s/it] 17%|█▋        | 118/714 [03:12<16:21,  1.65s/it] 17%|█▋        | 119/714 [03:14<16:15,  1.64s/it] 17%|█▋        | 120/714 [03:16<16:34,  1.67s/it] 17%|█▋        | 121/714 [03:17<17:05,  1.73s/it] 17%|█▋        | 122/714 [03:19<17:30,  1.77s/it] 17%|█▋        | 123/714 [03:21<17:10,  1.74s/it] 17%|█▋        | 124/714 [03:23<16:45,  1.71s/it] 18%|█▊        | 125/714 [03:24<16:32,  1.68s/it] 18%|█▊        | 126/714 [03:26<16:20,  1.67s/it] 18%|█▊        | 127/714 [03:27<16:06,  1.65s/it] 18%|█▊        | 128/714 [03:29<15:47,  1.62s/it] 18%|█▊        | 129/714 [03:31<15:57,  1.64s/it] 18%|█▊        | 130/714 [03:32<16:14,  1.67s/it] 18%|█▊        | 131/714 [03:34<16:57,  1.75s/it] 18%|█▊        | 132/714 [03:36<17:33,  1.81s/it] 19%|█▊        | 133/714 [03:38<17:34,  1.81s/it] 19%|█▉        | 134/714 [03:40<17:19,  1.79s/it] 19%|█▉        | 135/714 [03:42<17:29,  1.81s/it] 19%|█▉        | 136/714 [03:43<17:13,  1.79s/it] 19%|█▉        | 137/714 [03:45<16:46,  1.74s/it] 19%|█▉        | 138/714 [03:47<16:59,  1.77s/it] 19%|█▉        | 139/714 [03:49<17:13,  1.80s/it] 20%|█▉        | 140/714 [03:50<16:43,  1.75s/it] 20%|█▉        | 141/714 [03:52<16:55,  1.77s/it] 20%|█▉        | 142/714 [03:54<17:27,  1.83s/it] 20%|██        | 143/714 [03:56<17:27,  1.83s/it] 20%|██        | 144/714 [03:58<17:01,  1.79s/it] 20%|██        | 145/714 [04:00<16:52,  1.78s/it] 20%|██        | 146/714 [04:02<17:25,  1.84s/it] 21%|██        | 147/714 [04:03<17:07,  1.81s/it] 21%|██        | 148/714 [04:05<16:38,  1.76s/it] 21%|██        | 149/714 [04:07<16:36,  1.76s/it] 21%|██        | 150/714 [04:08<16:21,  1.74s/it] 21%|██        | 151/714 [04:10<15:52,  1.69s/it] 21%|██▏       | 152/714 [04:12<15:56,  1.70s/it] 21%|██▏       | 153/714 [04:14<16:24,  1.75s/it] 22%|██▏       | 154/714 [04:15<16:07,  1.73s/it] 22%|██▏       | 155/714 [04:17<15:39,  1.68s/it] 22%|██▏       | 156/714 [04:18<15:25,  1.66s/it] 22%|██▏       | 157/714 [04:20<15:38,  1.69s/it] 22%|██▏       | 158/714 [04:22<15:55,  1.72s/it] 22%|██▏       | 159/714 [04:23<15:26,  1.67s/it] 22%|██▏       | 160/714 [04:25<15:18,  1.66s/it] 23%|██▎       | 161/714 [04:27<15:17,  1.66s/it] 23%|██▎       | 162/714 [04:28<15:01,  1.63s/it] 23%|██▎       | 163/714 [04:30<15:05,  1.64s/it] 23%|██▎       | 164/714 [04:32<15:23,  1.68s/it] 23%|██▎       | 165/714 [04:33<15:22,  1.68s/it] 23%|██▎       | 166/714 [04:35<15:27,  1.69s/it] 23%|██▎       | 167/714 [04:37<15:40,  1.72s/it] 24%|██▎       | 168/714 [04:39<15:42,  1.73s/it] 24%|██▎       | 169/714 [04:41<15:51,  1.75s/it] 24%|██▍       | 170/714 [04:42<15:18,  1.69s/it] 24%|██▍       | 171/714 [04:44<14:54,  1.65s/it] 24%|██▍       | 172/714 [04:45<14:39,  1.62s/it] 24%|██▍       | 173/714 [04:47<14:57,  1.66s/it] 24%|██▍       | 174/714 [04:49<15:32,  1.73s/it] 25%|██▍       | 175/714 [04:50<15:23,  1.71s/it] 25%|██▍       | 176/714 [04:52<15:13,  1.70s/it] 25%|██▍       | 177/714 [04:54<15:06,  1.69s/it] 25%|██▍       | 178/714 [04:55<14:44,  1.65s/it] 25%|██▌       | 179/714 [04:57<14:48,  1.66s/it] 25%|██▌       | 180/714 [04:59<14:53,  1.67s/it] 25%|██▌       | 181/714 [05:00<14:37,  1.65s/it] 25%|██▌       | 182/714 [05:02<14:52,  1.68s/it] 26%|██▌       | 183/714 [05:04<15:07,  1.71s/it] 26%|██▌       | 184/714 [05:06<14:58,  1.69s/it] 26%|██▌       | 185/714 [05:07<15:10,  1.72s/it] 26%|██▌       | 186/714 [05:09<15:13,  1.73s/it] 26%|██▌       | 187/714 [05:11<15:01,  1.71s/it] 26%|██▋       | 188/714 [05:12<14:49,  1.69s/it] 26%|██▋       | 189/714 [05:14<14:57,  1.71s/it] 27%|██▋       | 190/714 [05:16<15:16,  1.75s/it] 27%|██▋       | 191/714 [05:18<15:24,  1.77s/it] 27%|██▋       | 192/714 [05:19<15:06,  1.74s/it] 27%|██▋       | 193/714 [05:21<15:00,  1.73s/it] 27%|██▋       | 194/714 [05:23<14:48,  1.71s/it] 27%|██▋       | 195/714 [05:25<14:43,  1.70s/it] 27%|██▋       | 196/714 [05:26<14:38,  1.70s/it] 28%|██▊       | 197/714 [05:28<14:56,  1.73s/it] 28%|██▊       | 198/714 [05:30<15:06,  1.76s/it] 28%|██▊       | 199/714 [05:32<14:53,  1.74s/it] 28%|██▊       | 200/714 [05:33<14:40,  1.71s/it] 28%|██▊       | 201/714 [05:35<14:37,  1.71s/it] 28%|██▊       | 202/714 [05:37<14:42,  1.72s/it] 28%|██▊       | 203/714 [05:39<15:05,  1.77s/it] 29%|██▊       | 204/714 [05:40<15:13,  1.79s/it] 29%|██▊       | 205/714 [05:42<15:25,  1.82s/it] 29%|██▉       | 206/714 [05:44<15:29,  1.83s/it] 29%|██▉       | 207/714 [05:46<15:23,  1.82s/it] 29%|██▉       | 208/714 [05:48<15:00,  1.78s/it] 29%|██▉       | 209/714 [05:49<14:47,  1.76s/it] 29%|██▉       | 210/714 [05:51<14:43,  1.75s/it] 30%|██▉       | 211/714 [05:53<15:03,  1.80s/it] 30%|██▉       | 212/714 [05:55<14:46,  1.77s/it] 30%|██▉       | 213/714 [05:56<14:17,  1.71s/it] 30%|██▉       | 214/714 [05:58<14:23,  1.73s/it] 30%|███       | 215/714 [06:00<15:15,  1.83s/it] 30%|███       | 216/714 [06:02<15:46,  1.90s/it] 30%|███       | 217/714 [06:04<16:07,  1.95s/it] 31%|███       | 218/714 [06:06<16:37,  2.01s/it] 31%|███       | 219/714 [06:09<18:05,  2.19s/it] 31%|███       | 220/714 [06:12<19:27,  2.36s/it] 31%|███       | 221/714 [06:14<20:07,  2.45s/it] 31%|███       | 222/714 [06:17<21:12,  2.59s/it] 31%|███       | 223/714 [06:21<23:49,  2.91s/it] 31%|███▏      | 224/714 [06:25<26:40,  3.27s/it] 32%|███▏      | 225/714 [06:29<28:10,  3.46s/it] 32%|███▏      | 226/714 [06:33<29:39,  3.65s/it] 32%|███▏      | 227/714 [06:37<31:12,  3.85s/it] 32%|███▏      | 228/714 [06:42<33:17,  4.11s/it] 32%|███▏      | 229/714 [06:47<34:47,  4.31s/it] 32%|███▏      | 230/714 [06:51<34:59,  4.34s/it] 32%|███▏      | 231/714 [06:56<35:29,  4.41s/it] 32%|███▏      | 232/714 [07:01<36:38,  4.56s/it] 33%|███▎      | 233/714 [07:07<40:09,  5.01s/it] 33%|███▎      | 234/714 [07:13<43:02,  5.38s/it] 33%|███▎      | 235/714 [07:19<43:35,  5.46s/it] 33%|███▎      | 236/714 [07:24<42:56,  5.39s/it] 33%|███▎      | 237/714 [07:29<42:13,  5.31s/it] 33%|███▎      | 238/714 [07:35<43:53,  5.53s/it] 33%|███▎      | 239/714 [07:41<43:54,  5.55s/it] 34%|███▎      | 240/714 [07:46<44:31,  5.64s/it] 34%|███▍      | 241/714 [07:51<42:16,  5.36s/it] 34%|███▍      | 242/714 [07:57<43:22,  5.51s/it] 34%|███▍      | 243/714 [08:03<43:49,  5.58s/it] 34%|███▍      | 244/714 [08:08<42:14,  5.39s/it] 34%|███▍      | 245/714 [08:13<42:15,  5.41s/it] 34%|███▍      | 246/714 [08:19<42:23,  5.43s/it] 35%|███▍      | 247/714 [08:25<43:48,  5.63s/it] 35%|███▍      | 248/714 [08:31<46:06,  5.94s/it] 35%|███▍      | 249/714 [08:38<46:28,  6.00s/it] 35%|███▌      | 250/714 [08:44<47:31,  6.14s/it] 35%|███▌      | 251/714 [08:50<47:48,  6.19s/it] 35%|███▌      | 252/714 [08:58<50:40,  6.58s/it] 35%|███▌      | 253/714 [09:05<51:21,  6.68s/it] 36%|███▌      | 254/714 [09:11<49:59,  6.52s/it] 36%|███▌      | 255/714 [09:17<48:59,  6.41s/it] 36%|███▌      | 256/714 [09:23<48:44,  6.39s/it] 36%|███▌      | 257/714 [09:31<50:38,  6.65s/it] 36%|███▌      | 258/714 [09:37<49:16,  6.48s/it] 36%|███▋      | 259/714 [09:42<46:57,  6.19s/it] 36%|███▋      | 260/714 [09:48<46:02,  6.08s/it] 37%|███▋      | 261/714 [09:55<46:55,  6.21s/it] 37%|███▋      | 262/714 [10:00<45:40,  6.06s/it] 37%|███▋      | 263/714 [10:07<46:40,  6.21s/it] 37%|███▋      | 264/714 [10:13<45:16,  6.04s/it] 37%|███▋      | 265/714 [10:19<46:52,  6.26s/it] 37%|███▋      | 266/714 [10:25<45:55,  6.15s/it] 37%|███▋      | 267/714 [10:31<44:41,  6.00s/it] 38%|███▊      | 268/714 [10:37<45:53,  6.17s/it] 38%|███▊      | 269/714 [10:45<47:55,  6.46s/it] 38%|███▊      | 270/714 [10:51<46:55,  6.34s/it] 38%|███▊      | 271/714 [10:57<46:34,  6.31s/it] 38%|███▊      | 272/714 [11:03<46:28,  6.31s/it] 38%|███▊      | 273/714 [11:10<46:27,  6.32s/it] 38%|███▊      | 274/714 [11:16<46:08,  6.29s/it] 39%|███▊      | 275/714 [11:23<47:07,  6.44s/it] 39%|███▊      | 276/714 [11:29<47:17,  6.48s/it] 39%|███▉      | 277/714 [11:35<46:46,  6.42s/it] 39%|███▉      | 278/714 [11:43<48:16,  6.64s/it] 39%|███▉      | 279/714 [11:50<49:07,  6.78s/it] 39%|███▉      | 280/714 [11:55<46:52,  6.48s/it] 39%|███▉      | 281/714 [11:59<40:10,  5.57s/it] 39%|███▉      | 282/714 [12:02<35:27,  4.93s/it] 40%|███▉      | 283/714 [12:06<31:55,  4.44s/it] 40%|███▉      | 284/714 [12:08<28:11,  3.93s/it] 40%|███▉      | 285/714 [12:11<24:38,  3.45s/it] 40%|████      | 286/714 [12:13<22:01,  3.09s/it] 40%|████      | 287/714 [12:15<20:18,  2.85s/it] 40%|████      | 288/714 [12:17<18:58,  2.67s/it] 40%|████      | 289/714 [12:20<17:48,  2.51s/it] 41%|████      | 290/714 [12:22<17:09,  2.43s/it] 41%|████      | 291/714 [12:24<16:43,  2.37s/it] 41%|████      | 292/714 [12:26<16:31,  2.35s/it] 41%|████      | 293/714 [12:28<15:58,  2.28s/it] 41%|████      | 294/714 [12:30<15:01,  2.15s/it] 41%|████▏     | 295/714 [12:32<14:46,  2.12s/it] 41%|████▏     | 296/714 [12:35<14:45,  2.12s/it] 42%|████▏     | 297/714 [12:36<14:20,  2.06s/it] 42%|████▏     | 298/714 [12:39<14:28,  2.09s/it] 42%|████▏     | 299/714 [12:41<14:29,  2.10s/it] 42%|████▏     | 300/714 [12:43<14:18,  2.07s/it] 42%|████▏     | 301/714 [12:45<14:11,  2.06s/it] 42%|████▏     | 302/714 [12:47<14:03,  2.05s/it] 42%|████▏     | 303/714 [12:49<14:04,  2.06s/it] 43%|████▎     | 304/714 [12:51<14:19,  2.10s/it] 43%|████▎     | 305/714 [12:53<14:28,  2.12s/it] 43%|████▎     | 306/714 [12:55<14:11,  2.09s/it] 43%|████▎     | 307/714 [12:57<13:43,  2.02s/it] 43%|████▎     | 308/714 [12:59<13:25,  1.98s/it] 43%|████▎     | 309/714 [13:01<13:05,  1.94s/it] 43%|████▎     | 310/714 [13:03<13:17,  1.98s/it] 44%|████▎     | 311/714 [13:05<13:24,  2.00s/it] 44%|████▎     | 312/714 [13:07<13:06,  1.96s/it] 44%|████▍     | 313/714 [13:09<12:55,  1.93s/it] 44%|████▍     | 314/714 [13:10<12:34,  1.89s/it] 44%|████▍     | 315/714 [13:12<12:03,  1.81s/it] 44%|████▍     | 316/714 [13:14<11:53,  1.79s/it] 44%|████▍     | 317/714 [13:16<12:00,  1.82s/it] 45%|████▍     | 318/714 [13:18<12:06,  1.83s/it] 45%|████▍     | 319/714 [13:19<11:52,  1.80s/it] 45%|████▍     | 320/714 [13:21<11:26,  1.74s/it] 45%|████▍     | 321/714 [13:23<11:27,  1.75s/it] 45%|████▌     | 322/714 [13:25<11:50,  1.81s/it] 45%|████▌     | 323/714 [13:27<11:59,  1.84s/it] 45%|████▌     | 324/714 [13:28<11:56,  1.84s/it] 46%|████▌     | 325/714 [13:30<12:00,  1.85s/it] 46%|████▌     | 326/714 [13:32<11:46,  1.82s/it] 46%|████▌     | 327/714 [13:34<11:39,  1.81s/it] 46%|████▌     | 328/714 [13:36<11:30,  1.79s/it] 46%|████▌     | 329/714 [13:37<11:26,  1.78s/it] 46%|████▌     | 330/714 [13:39<11:32,  1.80s/it] 46%|████▋     | 331/714 [13:41<11:39,  1.83s/it] 46%|████▋     | 332/714 [13:43<11:17,  1.77s/it] 47%|████▋     | 333/714 [13:44<11:03,  1.74s/it] 47%|████▋     | 334/714 [13:46<11:03,  1.75s/it] 47%|████▋     | 335/714 [13:48<11:04,  1.75s/it] 47%|████▋     | 336/714 [13:50<10:51,  1.72s/it] 47%|████▋     | 337/714 [13:51<10:42,  1.71s/it] 47%|████▋     | 338/714 [13:53<10:47,  1.72s/it] 47%|████▋     | 339/714 [13:55<11:02,  1.77s/it] 48%|████▊     | 340/714 [13:57<11:14,  1.80s/it] 48%|████▊     | 341/714 [13:58<11:04,  1.78s/it] 48%|████▊     | 342/714 [14:00<10:41,  1.73s/it] 48%|████▊     | 343/714 [14:02<10:53,  1.76s/it] 48%|████▊     | 344/714 [14:04<11:05,  1.80s/it] 48%|████▊     | 345/714 [14:05<10:46,  1.75s/it] 48%|████▊     | 346/714 [14:07<10:32,  1.72s/it] 49%|████▊     | 347/714 [14:09<10:23,  1.70s/it] 49%|████▊     | 348/714 [14:10<10:17,  1.69s/it] 49%|████▉     | 349/714 [14:12<10:13,  1.68s/it] 49%|████▉     | 350/714 [14:14<10:08,  1.67s/it] 49%|████▉     | 351/714 [14:15<10:16,  1.70s/it] 49%|████▉     | 352/714 [14:17<10:40,  1.77s/it] 49%|████▉     | 353/714 [14:19<10:52,  1.81s/it] 50%|████▉     | 354/714 [14:21<10:36,  1.77s/it] 50%|████▉     | 355/714 [14:23<10:34,  1.77s/it] 50%|████▉     | 356/714 [14:25<10:46,  1.81s/it] 50%|█████     | 357/714 [14:27<10:55,  1.84s/it] 50%|█████     | 358/714 [14:28<10:47,  1.82s/it] 50%|█████     | 359/714 [14:30<10:26,  1.76s/it] 50%|█████     | 360/714 [14:32<10:25,  1.77s/it] 51%|█████     | 361/714 [14:34<10:26,  1.77s/it] 51%|█████     | 362/714 [14:35<10:10,  1.73s/it] 51%|█████     | 363/714 [14:37<10:09,  1.74s/it] 51%|█████     | 364/714 [14:39<10:12,  1.75s/it] 51%|█████     | 365/714 [14:40<09:59,  1.72s/it] 51%|█████▏    | 366/714 [14:42<09:54,  1.71s/it] 51%|█████▏    | 367/714 [14:44<09:51,  1.71s/it] 52%|█████▏    | 368/714 [14:46<10:05,  1.75s/it] 52%|█████▏    | 369/714 [14:47<10:20,  1.80s/it] 52%|█████▏    | 370/714 [14:49<10:17,  1.80s/it] 52%|█████▏    | 371/714 [14:51<10:25,  1.82s/it] 52%|█████▏    | 372/714 [14:53<10:25,  1.83s/it] 52%|█████▏    | 373/714 [14:55<10:19,  1.82s/it] 52%|█████▏    | 374/714 [14:56<10:02,  1.77s/it] 53%|█████▎    | 375/714 [14:58<10:02,  1.78s/it] 53%|█████▎    | 376/714 [15:00<10:20,  1.84s/it] 53%|█████▎    | 377/714 [15:02<10:25,  1.85s/it] 53%|█████▎    | 378/714 [15:04<10:05,  1.80s/it] 53%|█████▎    | 379/714 [15:05<09:48,  1.76s/it] 53%|█████▎    | 380/714 [15:07<09:45,  1.75s/it] 53%|█████▎    | 381/714 [15:09<09:44,  1.76s/it] 54%|█████▎    | 382/714 [15:11<09:35,  1.73s/it] 54%|█████▎    | 383/714 [15:12<09:28,  1.72s/it] 54%|█████▍    | 384/714 [15:14<09:26,  1.72s/it] 54%|█████▍    | 385/714 [15:16<09:30,  1.73s/it] 54%|█████▍    | 386/714 [15:18<09:52,  1.81s/it] 54%|█████▍    | 387/714 [15:20<10:00,  1.84s/it] 54%|█████▍    | 388/714 [15:21<09:52,  1.82s/it] 54%|█████▍    | 389/714 [15:23<09:53,  1.83s/it] 55%|█████▍    | 390/714 [15:25<09:58,  1.85s/it] 55%|█████▍    | 391/714 [15:27<09:58,  1.85s/it] 55%|█████▍    | 392/714 [15:29<10:08,  1.89s/it] 55%|█████▌    | 393/714 [15:31<10:14,  1.91s/it] 55%|█████▌    | 394/714 [15:33<10:00,  1.88s/it] 55%|█████▌    | 395/714 [15:34<09:35,  1.81s/it] 55%|█████▌    | 396/714 [15:36<09:22,  1.77s/it] 56%|█████▌    | 397/714 [15:38<09:13,  1.74s/it] 56%|█████▌    | 398/714 [15:40<09:15,  1.76s/it] 56%|█████▌    | 399/714 [15:41<09:08,  1.74s/it] 56%|█████▌    | 400/714 [15:43<08:54,  1.70s/it] 56%|█████▌    | 401/714 [15:44<08:41,  1.67s/it] 56%|█████▋    | 402/714 [15:46<08:32,  1.64s/it] 56%|█████▋    | 403/714 [15:48<08:24,  1.62s/it] 57%|█████▋    | 404/714 [15:49<08:26,  1.63s/it] 57%|█████▋    | 405/714 [15:51<08:30,  1.65s/it] 57%|█████▋    | 406/714 [15:53<08:32,  1.66s/it] 57%|█████▋    | 407/714 [15:55<08:48,  1.72s/it] 57%|█████▋    | 408/714 [15:56<09:03,  1.78s/it] 57%|█████▋    | 409/714 [15:58<09:03,  1.78s/it] 57%|█████▋    | 410/714 [16:00<08:57,  1.77s/it] 58%|█████▊    | 411/714 [16:02<08:55,  1.77s/it] 58%|█████▊    | 412/714 [16:04<09:05,  1.81s/it] 58%|█████▊    | 413/714 [16:05<09:01,  1.80s/it] 58%|█████▊    | 414/714 [16:07<08:50,  1.77s/it] 58%|█████▊    | 415/714 [16:09<08:43,  1.75s/it] 58%|█████▊    | 416/714 [16:11<08:48,  1.77s/it] 58%|█████▊    | 417/714 [16:12<08:40,  1.75s/it] 59%|█████▊    | 418/714 [16:14<08:22,  1.70s/it] 59%|█████▊    | 419/714 [16:16<08:11,  1.67s/it] 59%|█████▉    | 420/714 [16:17<08:04,  1.65s/it] 59%|█████▉    | 421/714 [16:19<07:57,  1.63s/it] 59%|█████▉    | 422/714 [16:20<07:58,  1.64s/it] 59%|█████▉    | 423/714 [16:22<08:00,  1.65s/it] 59%|█████▉    | 424/714 [16:24<08:07,  1.68s/it] 60%|█████▉    | 425/714 [16:26<08:24,  1.75s/it] 60%|█████▉    | 426/714 [16:27<08:18,  1.73s/it] 60%|█████▉    | 427/714 [16:29<08:13,  1.72s/it] 60%|█████▉    | 428/714 [16:31<08:18,  1.74s/it] 60%|██████    | 429/714 [16:33<08:09,  1.72s/it] 60%|██████    | 430/714 [16:34<08:04,  1.70s/it] 60%|██████    | 431/714 [16:36<08:02,  1.70s/it] 61%|██████    | 432/714 [16:38<07:58,  1.70s/it] 61%|██████    | 433/714 [16:39<08:05,  1.73s/it] 61%|██████    | 434/714 [16:41<08:08,  1.74s/it] 61%|██████    | 435/714 [16:43<08:00,  1.72s/it] 61%|██████    | 436/714 [16:45<07:53,  1.70s/it] 61%|██████    | 437/714 [16:46<08:00,  1.74s/it] 61%|██████▏   | 438/714 [16:48<07:59,  1.74s/it] 61%|██████▏   | 439/714 [16:50<07:46,  1.70s/it] 62%|██████▏   | 440/714 [16:51<07:41,  1.69s/it] 62%|██████▏   | 441/714 [16:53<07:35,  1.67s/it] 62%|██████▏   | 442/714 [16:54<07:21,  1.62s/it] 62%|██████▏   | 443/714 [16:56<07:18,  1.62s/it] 62%|██████▏   | 444/714 [16:58<07:16,  1.62s/it] 62%|██████▏   | 445/714 [16:59<07:13,  1.61s/it] 62%|██████▏   | 446/714 [17:01<07:10,  1.60s/it] 63%|██████▎   | 447/714 [17:03<07:14,  1.63s/it] 63%|██████▎   | 448/714 [17:04<07:31,  1.70s/it] 63%|██████▎   | 449/714 [17:06<07:52,  1.78s/it] 63%|██████▎   | 450/714 [17:08<08:05,  1.84s/it] 63%|██████▎   | 451/714 [17:10<08:03,  1.84s/it] 63%|██████▎   | 452/714 [17:12<07:55,  1.82s/it] 63%|██████▎   | 453/714 [17:14<08:06,  1.86s/it] 64%|██████▎   | 454/714 [17:16<07:59,  1.85s/it] 64%|██████▎   | 455/714 [17:17<07:36,  1.76s/it] 64%|██████▍   | 456/714 [17:19<07:33,  1.76s/it] 64%|██████▍   | 457/714 [17:21<07:41,  1.80s/it] 64%|██████▍   | 458/714 [17:23<07:38,  1.79s/it] 64%|██████▍   | 459/714 [17:25<07:43,  1.82s/it] 64%|██████▍   | 460/714 [17:26<07:42,  1.82s/it] 65%|██████▍   | 461/714 [17:28<07:31,  1.79s/it] 65%|██████▍   | 462/714 [17:30<07:24,  1.76s/it] 65%|██████▍   | 463/714 [17:32<07:17,  1.74s/it] 65%|██████▍   | 464/714 [17:33<07:13,  1.73s/it] 65%|██████▌   | 465/714 [17:35<07:01,  1.69s/it] 65%|██████▌   | 466/714 [17:36<06:53,  1.67s/it] 65%|██████▌   | 467/714 [17:38<06:52,  1.67s/it] 66%|██████▌   | 468/714 [17:40<07:02,  1.72s/it] 66%|██████▌   | 469/714 [17:42<07:20,  1.80s/it] 66%|██████▌   | 470/714 [17:44<07:31,  1.85s/it] 66%|██████▌   | 471/714 [17:46<07:33,  1.87s/it] 66%|██████▌   | 472/714 [17:48<07:26,  1.85s/it] 66%|██████▌   | 473/714 [17:49<07:13,  1.80s/it] 66%|██████▋   | 474/714 [17:51<07:01,  1.76s/it] 67%|██████▋   | 475/714 [17:53<07:01,  1.76s/it] 67%|██████▋   | 476/714 [17:54<06:55,  1.74s/it] 67%|██████▋   | 477/714 [17:56<06:42,  1.70s/it] 67%|██████▋   | 478/714 [17:58<06:40,  1.70s/it] 67%|██████▋   | 479/714 [18:00<06:51,  1.75s/it] 67%|██████▋   | 480/714 [18:02<07:00,  1.80s/it] 67%|██████▋   | 481/714 [18:03<06:57,  1.79s/it] 68%|██████▊   | 482/714 [18:05<06:57,  1.80s/it] 68%|██████▊   | 483/714 [18:07<06:57,  1.81s/it] 68%|██████▊   | 484/714 [18:09<07:00,  1.83s/it] 68%|██████▊   | 485/714 [18:11<06:57,  1.82s/it] 68%|██████▊   | 486/714 [18:12<06:38,  1.75s/it] 68%|██████▊   | 487/714 [18:14<06:31,  1.73s/it] 68%|██████▊   | 488/714 [18:16<06:39,  1.77s/it] 68%|██████▊   | 489/714 [18:18<06:40,  1.78s/it] 69%|██████▊   | 490/714 [18:19<06:36,  1.77s/it] 69%|██████▉   | 491/714 [18:21<06:37,  1.78s/it] 69%|██████▉   | 492/714 [18:23<06:22,  1.72s/it] 69%|██████▉   | 493/714 [18:24<06:11,  1.68s/it] 69%|██████▉   | 494/714 [18:26<06:03,  1.65s/it] 69%|██████▉   | 495/714 [18:27<05:57,  1.63s/it] 69%|██████▉   | 496/714 [18:29<06:03,  1.67s/it] 70%|██████▉   | 497/714 [18:31<06:16,  1.74s/it] 70%|██████▉   | 498/714 [18:33<06:16,  1.74s/it] 70%|██████▉   | 499/714 [18:35<06:11,  1.73s/it] 70%|███████   | 500/714 [18:36<06:07,  1.72s/it] 70%|███████   | 501/714 [18:38<06:11,  1.75s/it] 70%|███████   | 502/714 [18:40<06:12,  1.76s/it] 70%|███████   | 503/714 [18:42<06:18,  1.80s/it] 71%|███████   | 504/714 [18:44<06:28,  1.85s/it] 71%|███████   | 505/714 [18:46<06:33,  1.88s/it] 71%|███████   | 506/714 [18:47<06:27,  1.87s/it] 71%|███████   | 507/714 [18:49<06:09,  1.78s/it] 71%|███████   | 508/714 [18:51<06:01,  1.75s/it] 71%|███████▏  | 509/714 [18:53<06:03,  1.77s/it] 71%|███████▏  | 510/714 [18:54<06:02,  1.78s/it] 72%|███████▏  | 511/714 [18:56<06:05,  1.80s/it] 72%|███████▏  | 512/714 [18:58<06:05,  1.81s/it] 72%|███████▏  | 513/714 [19:00<05:51,  1.75s/it] 72%|███████▏  | 514/714 [19:01<05:40,  1.70s/it] 72%|███████▏  | 515/714 [19:03<05:36,  1.69s/it] 72%|███████▏  | 516/714 [19:05<05:31,  1.67s/it] 72%|███████▏  | 517/714 [19:06<05:30,  1.68s/it] 73%|███████▎  | 518/714 [19:08<05:46,  1.77s/it] 73%|███████▎  | 519/714 [19:10<05:56,  1.83s/it] 73%|███████▎  | 520/714 [19:12<05:58,  1.85s/it] 73%|███████▎  | 521/714 [19:14<05:52,  1.83s/it] 73%|███████▎  | 522/714 [19:16<05:42,  1.79s/it] 73%|███████▎  | 523/714 [19:17<05:40,  1.78s/it] 73%|███████▎  | 524/714 [19:19<05:55,  1.87s/it] 74%|███████▎  | 525/714 [19:22<06:10,  1.96s/it] 74%|███████▎  | 526/714 [19:24<06:17,  2.01s/it] 74%|███████▍  | 527/714 [19:26<06:26,  2.07s/it] 74%|███████▍  | 528/714 [19:29<06:57,  2.25s/it] 74%|███████▍  | 529/714 [19:32<07:34,  2.46s/it] 74%|███████▍  | 530/714 [19:35<08:08,  2.66s/it] 74%|███████▍  | 531/714 [19:38<09:05,  2.98s/it] 75%|███████▍  | 532/714 [19:43<10:32,  3.47s/it] 75%|███████▍  | 533/714 [19:47<11:12,  3.72s/it] 75%|███████▍  | 534/714 [19:52<11:48,  3.94s/it] 75%|███████▍  | 535/714 [19:56<12:10,  4.08s/it] 75%|███████▌  | 536/714 [20:01<12:47,  4.31s/it] 75%|███████▌  | 537/714 [20:06<13:19,  4.52s/it] 75%|███████▌  | 538/714 [20:11<13:31,  4.61s/it] 75%|███████▌  | 539/714 [20:16<13:39,  4.69s/it] 76%|███████▌  | 540/714 [20:21<13:46,  4.75s/it] 76%|███████▌  | 541/714 [20:25<13:42,  4.76s/it] 76%|███████▌  | 542/714 [20:31<14:15,  4.97s/it] 76%|███████▌  | 543/714 [20:36<14:25,  5.06s/it] 76%|███████▌  | 544/714 [20:42<14:46,  5.21s/it] 76%|███████▋  | 545/714 [20:47<15:05,  5.36s/it] 76%|███████▋  | 546/714 [20:53<14:50,  5.30s/it] 77%|███████▋  | 547/714 [20:59<15:37,  5.61s/it] 77%|███████▋  | 548/714 [21:04<15:13,  5.50s/it] 77%|███████▋  | 549/714 [21:09<14:54,  5.42s/it] 77%|███████▋  | 550/714 [21:16<15:48,  5.78s/it] 77%|███████▋  | 551/714 [21:22<15:33,  5.73s/it] 77%|███████▋  | 552/714 [21:28<15:54,  5.89s/it] 77%|███████▋  | 553/714 [21:33<14:53,  5.55s/it] 78%|███████▊  | 554/714 [21:39<15:10,  5.69s/it] 78%|███████▊  | 555/714 [21:45<15:37,  5.90s/it] 78%|███████▊  | 556/714 [21:51<15:56,  6.05s/it] 78%|███████▊  | 557/714 [21:58<16:34,  6.33s/it] 78%|███████▊  | 558/714 [22:04<15:48,  6.08s/it] 78%|███████▊  | 559/714 [22:10<15:21,  5.94s/it] 78%|███████▊  | 560/714 [22:16<15:22,  5.99s/it] 79%|███████▊  | 561/714 [22:21<14:55,  5.85s/it] 79%|███████▊  | 562/714 [22:27<15:07,  5.97s/it] 79%|███████▉  | 563/714 [22:33<15:04,  5.99s/it] 79%|███████▉  | 564/714 [22:40<15:40,  6.27s/it] 79%|███████▉  | 565/714 [22:47<15:59,  6.44s/it] 79%|███████▉  | 566/714 [22:54<16:06,  6.53s/it] 79%|███████▉  | 567/714 [23:01<16:09,  6.59s/it] 80%|███████▉  | 568/714 [23:07<16:00,  6.58s/it] 80%|███████▉  | 569/714 [23:14<15:52,  6.57s/it] 80%|███████▉  | 570/714 [23:20<15:19,  6.39s/it] 80%|███████▉  | 571/714 [23:26<15:05,  6.33s/it] 80%|████████  | 572/714 [23:33<15:10,  6.41s/it] 80%|████████  | 573/714 [23:39<15:26,  6.57s/it] 80%|████████  | 574/714 [23:46<14:59,  6.43s/it] 81%|████████  | 575/714 [23:52<14:53,  6.43s/it] 81%|████████  | 576/714 [23:59<15:09,  6.59s/it] 81%|████████  | 577/714 [24:06<15:27,  6.77s/it] 81%|████████  | 578/714 [24:12<14:44,  6.51s/it] 81%|████████  | 579/714 [24:19<14:39,  6.52s/it] 81%|████████  | 580/714 [24:24<14:02,  6.28s/it] 81%|████████▏ | 581/714 [24:32<14:33,  6.57s/it] 82%|████████▏ | 582/714 [24:38<14:39,  6.66s/it] 82%|████████▏ | 583/714 [24:45<14:10,  6.49s/it] 82%|████████▏ | 584/714 [24:51<13:53,  6.41s/it] 82%|████████▏ | 585/714 [24:57<13:36,  6.33s/it] 82%|████████▏ | 586/714 [25:04<14:18,  6.71s/it] 82%|████████▏ | 587/714 [25:11<14:19,  6.77s/it] 82%|████████▏ | 588/714 [25:18<14:13,  6.77s/it] 82%|████████▏ | 589/714 [25:26<14:38,  7.03s/it] 83%|████████▎ | 590/714 [25:31<13:16,  6.42s/it] 83%|████████▎ | 591/714 [25:34<11:28,  5.59s/it] 83%|████████▎ | 592/714 [25:37<09:28,  4.66s/it] 83%|████████▎ | 593/714 [25:40<08:10,  4.05s/it] 83%|████████▎ | 594/714 [25:43<07:25,  3.71s/it] 83%|████████▎ | 595/714 [25:45<06:49,  3.44s/it] 83%|████████▎ | 596/714 [25:48<06:05,  3.09s/it] 84%|████████▎ | 597/714 [25:50<05:27,  2.80s/it] 84%|████████▍ | 598/714 [25:52<05:04,  2.63s/it] 84%|████████▍ | 599/714 [25:54<04:54,  2.56s/it] 84%|████████▍ | 600/714 [25:56<04:31,  2.38s/it] 84%|████████▍ | 601/714 [25:58<04:21,  2.32s/it] 84%|████████▍ | 602/714 [26:01<04:21,  2.33s/it] 84%|████████▍ | 603/714 [26:03<04:15,  2.30s/it] 85%|████████▍ | 604/714 [26:05<04:10,  2.27s/it] 85%|████████▍ | 605/714 [26:08<04:09,  2.29s/it] 85%|████████▍ | 606/714 [26:10<04:08,  2.30s/it] 85%|████████▌ | 607/714 [26:12<04:00,  2.25s/it] 85%|████████▌ | 608/714 [26:14<03:44,  2.12s/it] 85%|████████▌ | 609/714 [26:16<03:29,  1.99s/it] 85%|████████▌ | 610/714 [26:18<03:25,  1.98s/it] 86%|████████▌ | 611/714 [26:20<03:24,  1.98s/it] 86%|████████▌ | 612/714 [26:21<03:18,  1.94s/it] 86%|████████▌ | 613/714 [26:23<03:17,  1.95s/it] 86%|████████▌ | 614/714 [26:25<03:18,  1.99s/it] 86%|████████▌ | 615/714 [26:28<03:21,  2.03s/it] 86%|████████▋ | 616/714 [26:29<03:15,  1.99s/it] 86%|████████▋ | 617/714 [26:31<03:11,  1.97s/it] 87%|████████▋ | 618/714 [26:33<03:12,  2.01s/it] 87%|████████▋ | 619/714 [26:35<03:09,  2.00s/it] 87%|████████▋ | 620/714 [26:37<03:07,  1.99s/it] 87%|████████▋ | 621/714 [26:39<03:06,  2.01s/it] 87%|████████▋ | 622/714 [26:42<03:07,  2.04s/it] 87%|████████▋ | 623/714 [26:43<02:58,  1.96s/it] 87%|████████▋ | 624/714 [26:45<02:47,  1.86s/it] 88%|████████▊ | 625/714 [26:47<02:40,  1.80s/it] 88%|████████▊ | 626/714 [26:48<02:34,  1.75s/it] 88%|████████▊ | 627/714 [26:50<02:29,  1.72s/it] 88%|████████▊ | 628/714 [26:52<02:28,  1.73s/it] 88%|████████▊ | 629/714 [26:53<02:27,  1.74s/it] 88%|████████▊ | 630/714 [26:55<02:24,  1.72s/it] 88%|████████▊ | 631/714 [26:57<02:26,  1.76s/it] 89%|████████▊ | 632/714 [26:59<02:32,  1.86s/it] 89%|████████▊ | 633/714 [27:01<02:33,  1.90s/it] 89%|████████▉ | 634/714 [27:03<02:28,  1.86s/it] 89%|████████▉ | 635/714 [27:04<02:22,  1.80s/it] 89%|████████▉ | 636/714 [27:06<02:17,  1.76s/it] 89%|████████▉ | 637/714 [27:08<02:13,  1.74s/it] 89%|████████▉ | 638/714 [27:10<02:10,  1.72s/it] 89%|████████▉ | 639/714 [27:11<02:12,  1.76s/it] 90%|████████▉ | 640/714 [27:13<02:16,  1.84s/it] 90%|████████▉ | 641/714 [27:15<02:13,  1.83s/it] 90%|████████▉ | 642/714 [27:17<02:10,  1.82s/it] 90%|█████████ | 643/714 [27:19<02:09,  1.82s/it] 90%|█████████ | 644/714 [27:20<02:04,  1.77s/it] 90%|█████████ | 645/714 [27:22<02:03,  1.79s/it] 90%|█████████ | 646/714 [27:24<02:03,  1.82s/it] 91%|█████████ | 647/714 [27:26<01:58,  1.76s/it] 91%|█████████ | 648/714 [27:28<01:57,  1.79s/it] 91%|█████████ | 649/714 [27:30<02:00,  1.86s/it] 91%|█████████ | 650/714 [27:32<02:01,  1.90s/it] 91%|█████████ | 651/714 [27:34<02:02,  1.95s/it] 91%|█████████▏| 652/714 [27:36<01:58,  1.91s/it] 91%|█████████▏| 653/714 [27:37<01:52,  1.84s/it] 92%|█████████▏| 654/714 [27:39<01:50,  1.84s/it] 92%|█████████▏| 655/714 [27:41<01:49,  1.86s/it] 92%|█████████▏| 656/714 [27:43<01:48,  1.87s/it] 92%|█████████▏| 657/714 [27:45<01:47,  1.88s/it] 92%|█████████▏| 658/714 [27:47<01:45,  1.88s/it] 92%|█████████▏| 659/714 [27:48<01:41,  1.85s/it] 92%|█████████▏| 660/714 [27:50<01:37,  1.80s/it] 93%|█████████▎| 661/714 [27:52<01:36,  1.82s/it] 93%|█████████▎| 662/714 [27:54<01:35,  1.84s/it] 93%|█████████▎| 663/714 [27:56<01:31,  1.79s/it] 93%|█████████▎| 664/714 [27:57<01:30,  1.81s/it] 93%|█████████▎| 665/714 [27:59<01:31,  1.87s/it] 93%|█████████▎| 666/714 [28:01<01:29,  1.87s/it] 93%|█████████▎| 667/714 [28:03<01:29,  1.90s/it] 94%|█████████▎| 668/714 [28:05<01:28,  1.93s/it] 94%|█████████▎| 669/714 [28:07<01:26,  1.92s/it] 94%|█████████▍| 670/714 [28:09<01:22,  1.88s/it] 94%|█████████▍| 671/714 [28:11<01:18,  1.82s/it] 94%|█████████▍| 672/714 [28:12<01:16,  1.81s/it] 94%|█████████▍| 673/714 [28:14<01:14,  1.81s/it] 94%|█████████▍| 674/714 [28:16<01:12,  1.81s/it] 95%|█████████▍| 675/714 [28:18<01:09,  1.78s/it] 95%|█████████▍| 676/714 [28:19<01:06,  1.76s/it] 95%|█████████▍| 677/714 [28:21<01:04,  1.74s/it] 95%|█████████▍| 678/714 [28:23<01:01,  1.72s/it] 95%|█████████▌| 679/714 [28:24<00:59,  1.70s/it] 95%|█████████▌| 680/714 [28:26<00:57,  1.70s/it] 95%|█████████▌| 681/714 [28:28<00:57,  1.74s/it] 96%|█████████▌| 682/714 [28:30<00:55,  1.72s/it] 96%|█████████▌| 683/714 [28:31<00:53,  1.73s/it] 96%|█████████▌| 684/714 [28:33<00:53,  1.77s/it] 96%|█████████▌| 685/714 [28:35<00:53,  1.84s/it] 96%|█████████▌| 686/714 [28:37<00:52,  1.88s/it] 96%|█████████▌| 687/714 [28:39<00:51,  1.91s/it] 96%|█████████▋| 688/714 [28:41<00:48,  1.88s/it] 96%|█████████▋| 689/714 [28:43<00:45,  1.82s/it] 97%|█████████▋| 690/714 [28:44<00:43,  1.79s/it] 97%|█████████▋| 691/714 [28:46<00:39,  1.74s/it] 97%|█████████▋| 692/714 [28:48<00:37,  1.72s/it] 97%|█████████▋| 693/714 [28:50<00:36,  1.74s/it] 97%|█████████▋| 694/714 [28:51<00:35,  1.78s/it] 97%|█████████▋| 695/714 [28:53<00:34,  1.84s/it] 97%|█████████▋| 696/714 [28:55<00:33,  1.88s/it] 98%|█████████▊| 697/714 [28:57<00:32,  1.91s/it] 98%|█████████▊| 698/714 [28:59<00:30,  1.88s/it] 98%|█████████▊| 699/714 [29:01<00:27,  1.82s/it] 98%|█████████▊| 700/714 [29:03<00:24,  1.78s/it] 98%|█████████▊| 701/714 [29:04<00:22,  1.72s/it] 98%|█████████▊| 702/714 [29:06<00:20,  1.73s/it] 98%|█████████▊| 703/714 [29:08<00:19,  1.80s/it] 99%|█████████▊| 704/714 [29:10<00:18,  1.80s/it] 99%|█████████▊| 705/714 [29:11<00:15,  1.73s/it] 99%|█████████▉| 706/714 [29:13<00:13,  1.74s/it] 99%|█████████▉| 707/714 [29:15<00:12,  1.76s/it] 99%|█████████▉| 708/714 [29:16<00:10,  1.74s/it] 99%|█████████▉| 709/714 [29:18<00:08,  1.76s/it] 99%|█████████▉| 710/714 [29:20<00:06,  1.74s/it]100%|█████████▉| 711/714 [29:22<00:05,  1.72s/it]100%|█████████▉| 712/714 [29:23<00:03,  1.74s/it]100%|█████████▉| 713/714 [29:25<00:01,  1.75s/it]100%|██████████| 714/714 [29:27<00:00,  1.75s/it]100%|██████████| 714/714 [29:28<00:00,  2.48s/it]
Map:   0%|          | 0/714 [00:00<?, ? examples/s]Map:  39%|███▉      | 278/714 [00:00<00:00, 2733.75 examples/s]Map:  77%|███████▋  | 552/714 [00:00<00:00, 2731.79 examples/s]Map: 100%|██████████| 714/714 [00:00<00:00, 1876.11 examples/s]
***** eval metrics *****
  eval_loss               =     0.1256
  eval_runtime            = 0:29:29.37
  eval_samples            =        714
  eval_samples_per_second =      0.404
  eval_steps_per_second   =      0.404
  eval_tokens             =     750989
+ WANDB_DISABLED=true
+ python -u example/instruction_tuning_pipeline/finetune_clm.py --model_name_or_path /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf --train_file /home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/train.parquet --validation_file /home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/valid.parquet --prompt_type viggo_textformat --prompt_file_viggo_textformat /home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/prompt_mul --max_seq_length 1200 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --logging_steps 100 --save_total_limit 1 --log_level info --output_dir /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora --peft lora --trust_remote_code True --fp16 --load_in_8bit False --resume_peft /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora --save_merged_model True
+ tee /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/log/Llama-2-7b-chat-hf-lora-1epoch-merge.log
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
finetune_args is 
 FinetuneArguments(lora_rank=8, lora_alpha=16, lora_dropout=0.05, lora_target_modules=None, adapter_layers=30, adapter_len=10, num_virtual_tokens=10, ptun_hidden_size=1024, peft='lora', resume_peft='/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora', delta=None, profile=False, train_on_inputs=True, habana=False, debugs=False, save_merged_model=True, merge_model_code_dir='', load_in_8bit=False, input_sentence='', output_length_limit=20, prompt_type='viggo_textformat', prompt_file_viggo_textformat='/home/vmagent/app/LLM_datapre/data//textformat/data/viggo_mul/prompt_mul')
2024-02-23 19:01:30,066 - __main__ - WARNING - Process rank: 0, device: cuda:0
distributed training: True, 16-bits training: True
2024-02-23 19:01:30,067 - __main__ - INFO - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora/runs/Feb23_19-01-30_vsr134,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=100,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=1,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|configuration_utils.py:713] 2024-02-23 19:01:30,067 >> loading configuration file /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf/config.json
[INFO|configuration_utils.py:775] 2024-02-23 19:01:30,068 >> Model config LlamaConfig {
  "_name_or_path": "/home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.32.1",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:1850] 2024-02-23 19:01:30,070 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:1850] 2024-02-23 19:01:30,070 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:1850] 2024-02-23 19:01:30,070 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:1850] 2024-02-23 19:01:30,070 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:1850] 2024-02-23 19:01:30,070 >> loading file tokenizer_config.json
/opt/conda/lib/python3.10/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=None' instead.
  warnings.warn(
-----------------0-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.

##Output##

------------------
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

-----------------1-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
Dirt: Showdown is a sport racing game that was released in 2012. The game is available on PlayStation, Xbox, and PC, and it has an ESRB Rating of E 10+ (for Everyone 10 and Older). However, it is not yet available as a Steam, Linux, or Mac release.
Crysis is an action-adventure first person shooter developed by Crytek Frankfurt. It was originally released on PlayStation, Xbox, and PC and is available on Steam, but is not available for Linux or Mac.
Are you talking about the Heroes of Might and Magic III: The Restoration of Erathia that has been released on Linux though not available on Steam?

##Output##

------------------
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]
name[Crysis], developer[Crytek Frankfurt], genres[action-adventure, shooter], player_perspective[first person], platforms[PlayStation, Xbox, PC], available_on_steam[yes], has_linux_release[no], has_mac_release[no]
name[Heroes of Might and Magic III: The Restoration of Erathia], available_on_steam[no], has_linux_release[yes]

-----------------2-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
Dirt: Showdown is a driving/racing sport game released in 2012. It is rated E 10+, and is available on PlayStation, Xbox and PC, but not on Steam, Mac, or Linux.
Tetris from 1986 was played in the side view but didn't have multiplayer. It was an arcade, puzzle, strategy game by Spectrum HoloByte, Inc.
Tony Hawk's Pro Skater 3 is an average third person sports game that came out in 2001. It was developed by Neversoft Entertainment and rated T (for Teen).

##Output##

------------------
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]
name[Tetris], release_year[1986], developer[Spectrum HoloByte, Inc], genres[arcade, puzzle, strategy], player_perspective[side view], has_multiplayer[no]
name[Tony Hawk's Pro Skater 3], release_year[2001], developer[Neversoft Entertainment], esrb[T (for Teen)], rating[average], genres[sport], player_perspective[third person]

-----------------0-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
SpellForce 3 is a pretty bad game. The developer Grimlore Games is clearly a bunch of no-talent hacks, and 2017 was a terrible year for games anyway.

##Output##

------------------
name[SpellForce 3], release_year[2017], developer[Grimlore Games], rating[poor]

-----------------1-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
I wanted to like Grimlore Games' 2017 entry, but in SpellForce 3 they just didn't get anything right.
Do you like EA Digital Illusions CE's games with multiplayer in them like Mirror's Edge Catalyst?
You recently said you liked Commandos: Behind Enemy Lines, which is on Steam. Do you normally like playing PC games like this?
Nightshade is a text adventure game by Red Entertainment Corporation that came out in 2017. This game doesn't have multiplayer.
Metro 2033 is an role-playing action shooter game that was released in 2010. It can be played on Xbox and PC and is on Steam. It hasn't been released on Linux or Mac. It can only be played as a single-player.

##Output##

------------------
name[SpellForce 3], release_year[2017], developer[Grimlore Games], rating[poor]
name[Mirror's Edge Catalyst], developer[EA Digital Illusions CE], has_multiplayer[yes]
name[Commandos: Behind Enemy Lines], rating[good], platforms[PC], available_on_steam[yes]
name[Nightshade], release_year[2017], developer[Red Entertainment Corporation], genres[text adventure], has_multiplayer[no]
name[Metro 2033], release_year[2010], genres[action, role-playing, shooter], has_multiplayer[no], platforms[Xbox, PC], available_on_steam[yes], has_linux_release[no], has_mac_release[no]

-----------------2-------------------
Given a set of sentences, for each sentence construct its underlying meaning representation with several attributes and attribute values.

The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']. The order your list the attributes within the function must follow the order listed above. For example the 'name' attribute must always come  before the 'exp_release_date' attribute, and so forth.

For each attribute, fill in the corresponding value of the attribute within brackets.

Each input sentence will be given line by line (can skip empty line if there exists),  please also output the corresponding result line by line following the same order.

Input sentences will be given after "##Input##", you are expected to output the result after "##Output##". Do not include "##Output##" in your result and do not give any other sentence except the required result.

A couple of examples are below. 

Example (1)
##Input##
Dirt: Showdown from 2012 is a sport racing game for the PlayStation, Xbox, PC rated E 10+ (for Everyone 10 and Older). It's not available on Steam, Linux, or Mac.
##Output## 
name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no]

Example (2)
##Input##
Were there even any terrible games in 2014?
Adventure games that combine platforming and puzzles can be frustrating to play, but the side view perspective is perfect for them. That's why I enjoyed playing Little Nightmares.
Since we're on the subject of games developed by Telltale Games, I'm wondering, have you played The Wolf Among Us?
##Output##
release_year[2014], specifier[terrible]
name[Little Nightmares], rating[good], genres[adventure, platformer, puzzle], player_perspective[side view]
name[The Wolf Among Us], developer[Telltale Games]

Example (3)
##Input##
Layers of Fear, the indie first person point-and-click adventure game?
I bet you like it when you can play games on Steam, like Worms: Reloaded, right?
I recall you saying that you really enjoyed The Legend of Zelda: Ocarina of Time. Are you typically a big fan of games on Nintendo rated E (for Everyone)?
So what is it about the games that were released in 2005 that you find so excellent?
Do you think Mac is a better gaming platform than others?
##Output##
name[Layers of Fear], genres[adventure, indie, point-and-click], player_perspective[first person]
name[Worms: Reloaded], available_on_steam[yes]
name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo]
release_year[2005], rating[excellent]
has_mac_release[]

Give the output for the following sentences:
##Input##
I think SpellForce 3 is really, really bad. It's made by Grimlore Games and their games are always terrible, but it also came out in 2017, which was an especially bad year for them.
FIFA 12 is so-so in my opinion. EA Canada is an okay developer, but they don't really know how to bring out the full potential of the Xbox.
Speaking of multiplayer sports games, have you heard of Tony Hawk's Pro Skater 3?

##Output##

------------------
name[SpellForce 3], release_year[2017], developer[Grimlore Games], rating[poor]
name[FIFA 12], developer[EA Canada], rating[average], platforms[Xbox]
name[Tony Hawk's Pro Skater 3], genres[sport], has_multiplayer[yes]

[INFO|modeling_utils.py:2776] 2024-02-23 19:01:31,719 >> loading weights file /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf/model.safetensors.index.json
[INFO|modeling_utils.py:1191] 2024-02-23 19:01:31,719 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.
[INFO|configuration_utils.py:768] 2024-02-23 19:01:31,720 >> Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "transformers_version": "4.32.1"
}

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.57it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.34it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.97it/s]
[INFO|modeling_utils.py:3551] 2024-02-23 19:01:32,388 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:3559] 2024-02-23 19:01:32,388 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:728] 2024-02-23 19:01:32,390 >> loading configuration file /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf/generation_config.json
[INFO|configuration_utils.py:768] 2024-02-23 19:01:32,390 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9,
  "transformers_version": "4.32.1"
}

Map:   0%|          | 0/4648 [00:00<?, ? examples/s]Map:  22%|██▏       | 1000/4648 [00:00<00:03, 1059.56 examples/s]Map:  43%|████▎     | 2000/4648 [00:01<00:02, 1152.82 examples/s]Map:  65%|██████▍   | 3000/4648 [00:02<00:01, 1159.87 examples/s]Map:  86%|████████▌ | 4000/4648 [00:03<00:00, 1179.77 examples/s]Map: 100%|██████████| 4648/4648 [00:03<00:00, 1190.55 examples/s]Map: 100%|██████████| 4648/4648 [00:03<00:00, 1165.74 examples/s]
Map:   0%|          | 0/714 [00:00<?, ? examples/s]Map: 100%|██████████| 714/714 [00:00<00:00, 1258.05 examples/s]Map: 100%|██████████| 714/714 [00:00<00:00, 1231.68 examples/s]
2024-02-23 19:01:37,043 - __main__ - INFO - Using data collator of type DataCollatorForSeq2Seq
2024-02-23 19:01:51,015 - __main__ - INFO - ***original optimized model parameter***
trainable params: 0 || all params: 6,742,609,920 || trainable%: 0.0
copy base model config to /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora/merged_model
remove unnecessary file from /home/vmagent/app/LLM_datapre/data//Llama-2-7b-chat-hf
Save merged model to /home/vmagent/app/LLM_datapre/data//textformat/models/viggo_mul/models/Llama-2-7b-chat-hf-lora/merged_model
2024-02-23 19:02:49,726 - __main__ - INFO - *** Evaluate ***
[INFO|trainer.py:750] 2024-02-23 19:02:49,727 >> The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt_sources, prompt_targets. If prompt_sources, prompt_targets are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.
[INFO|trainer.py:3119] 2024-02-23 19:02:49,736 >> ***** Running Evaluation *****
[INFO|trainer.py:3121] 2024-02-23 19:02:49,736 >>   Num examples = 714
[INFO|trainer.py:3124] 2024-02-23 19:02:49,736 >>   Batch size = 1
[WARNING|logging.py:290] 2024-02-23 19:02:49,740 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 0/714 [00:00<?, ?it/s]  0%|          | 2/714 [00:00<01:39,  7.18it/s]  0%|          | 3/714 [00:00<02:28,  4.79it/s]  1%|          | 4/714 [00:00<02:51,  4.14it/s]  1%|          | 5/714 [00:01<03:09,  3.74it/s]  1%|          | 6/714 [00:01<03:15,  3.62it/s]  1%|          | 7/714 [00:01<03:16,  3.60it/s]  1%|          | 8/714 [00:02<03:12,  3.67it/s]  1%|▏         | 9/714 [00:02<03:08,  3.74it/s]  1%|▏         | 10/714 [00:02<03:05,  3.80it/s]  2%|▏         | 11/714 [00:02<03:00,  3.90it/s]  2%|▏         | 12/714 [00:03<03:01,  3.87it/s]  2%|▏         | 13/714 [00:03<03:09,  3.70it/s]  2%|▏         | 14/714 [00:03<03:06,  3.75it/s]  2%|▏         | 15/714 [00:03<03:08,  3.72it/s]  2%|▏         | 16/714 [00:04<03:13,  3.60it/s]  2%|▏         | 17/714 [00:04<03:10,  3.66it/s]  3%|▎         | 18/714 [00:04<03:09,  3.67it/s]  3%|▎         | 19/714 [00:04<03:13,  3.60it/s]  3%|▎         | 20/714 [00:05<03:14,  3.56it/s]  3%|▎         | 21/714 [00:05<03:11,  3.62it/s]  3%|▎         | 22/714 [00:05<03:09,  3.66it/s]  3%|▎         | 23/714 [00:06<03:13,  3.57it/s]  3%|▎         | 24/714 [00:06<03:16,  3.51it/s]  4%|▎         | 25/714 [00:06<03:14,  3.55it/s]  4%|▎         | 26/714 [00:06<03:17,  3.49it/s]  4%|▍         | 27/714 [00:07<03:14,  3.53it/s]  4%|▍         | 28/714 [00:07<03:07,  3.66it/s]  4%|▍         | 29/714 [00:07<03:13,  3.54it/s]  4%|▍         | 30/714 [00:08<03:16,  3.48it/s]  4%|▍         | 31/714 [00:08<03:12,  3.55it/s]  4%|▍         | 32/714 [00:08<03:15,  3.48it/s]  5%|▍         | 33/714 [00:08<03:20,  3.39it/s]  5%|▍         | 34/714 [00:09<03:20,  3.39it/s]  5%|▍         | 35/714 [00:09<03:21,  3.36it/s]  5%|▌         | 36/714 [00:09<03:24,  3.32it/s]  5%|▌         | 37/714 [00:10<03:22,  3.34it/s]  5%|▌         | 38/714 [00:10<03:20,  3.38it/s]  5%|▌         | 39/714 [00:10<03:20,  3.37it/s]  6%|▌         | 40/714 [00:11<03:22,  3.32it/s]  6%|▌         | 41/714 [00:11<03:19,  3.38it/s]  6%|▌         | 42/714 [00:11<03:13,  3.47it/s]  6%|▌         | 43/714 [00:11<03:14,  3.44it/s]  6%|▌         | 44/714 [00:12<03:17,  3.40it/s]  6%|▋         | 45/714 [00:12<03:21,  3.31it/s]  6%|▋         | 46/714 [00:12<03:23,  3.29it/s]  7%|▋         | 47/714 [00:13<03:18,  3.36it/s]  7%|▋         | 48/714 [00:13<03:12,  3.46it/s]  7%|▋         | 49/714 [00:13<03:12,  3.45it/s]  7%|▋         | 50/714 [00:13<03:09,  3.50it/s]  7%|▋         | 51/714 [00:14<03:04,  3.59it/s]  7%|▋         | 52/714 [00:14<03:05,  3.57it/s]  7%|▋         | 53/714 [00:14<03:08,  3.51it/s]  8%|▊         | 54/714 [00:15<03:04,  3.57it/s]  8%|▊         | 55/714 [00:15<03:04,  3.57it/s]  8%|▊         | 56/714 [00:15<02:59,  3.66it/s]  8%|▊         | 57/714 [00:15<03:00,  3.64it/s]  8%|▊         | 58/714 [00:16<03:07,  3.50it/s]  8%|▊         | 59/714 [00:16<03:07,  3.50it/s]  8%|▊         | 60/714 [00:16<03:03,  3.56it/s]  9%|▊         | 61/714 [00:17<03:02,  3.58it/s]  9%|▊         | 62/714 [00:17<03:01,  3.59it/s]  9%|▉         | 63/714 [00:17<03:06,  3.49it/s]  9%|▉         | 64/714 [00:17<03:04,  3.51it/s]  9%|▉         | 65/714 [00:18<03:04,  3.53it/s]  9%|▉         | 66/714 [00:18<03:07,  3.46it/s]  9%|▉         | 67/714 [00:18<03:01,  3.56it/s] 10%|▉         | 68/714 [00:19<02:58,  3.62it/s] 10%|▉         | 69/714 [00:19<02:55,  3.67it/s] 10%|▉         | 70/714 [00:19<02:52,  3.74it/s] 10%|▉         | 71/714 [00:19<02:54,  3.69it/s] 10%|█         | 72/714 [00:20<03:03,  3.49it/s] 10%|█         | 73/714 [00:20<03:09,  3.38it/s] 10%|█         | 74/714 [00:20<03:07,  3.41it/s] 11%|█         | 75/714 [00:21<03:01,  3.53it/s] 11%|█         | 76/714 [00:21<03:07,  3.40it/s] 11%|█         | 77/714 [00:21<03:08,  3.38it/s] 11%|█         | 78/714 [00:21<03:06,  3.42it/s] 11%|█         | 79/714 [00:22<03:09,  3.36it/s] 11%|█         | 80/714 [00:22<03:07,  3.37it/s] 11%|█▏        | 81/714 [00:22<03:05,  3.42it/s] 11%|█▏        | 82/714 [00:23<02:59,  3.52it/s] 12%|█▏        | 83/714 [00:23<02:58,  3.53it/s] 12%|█▏        | 84/714 [00:23<03:03,  3.44it/s] 12%|█▏        | 85/714 [00:23<03:02,  3.44it/s] 12%|█▏        | 86/714 [00:24<03:05,  3.39it/s] 12%|█▏        | 87/714 [00:24<03:09,  3.31it/s] 12%|█▏        | 88/714 [00:24<03:09,  3.31it/s] 12%|█▏        | 89/714 [00:25<03:06,  3.36it/s] 13%|█▎        | 90/714 [00:25<03:06,  3.35it/s] 13%|█▎        | 91/714 [00:25<03:00,  3.44it/s] 13%|█▎        | 92/714 [00:26<02:59,  3.47it/s] 13%|█▎        | 93/714 [00:26<02:53,  3.58it/s] 13%|█▎        | 94/714 [00:26<02:51,  3.61it/s] 13%|█▎        | 95/714 [00:26<02:55,  3.54it/s] 13%|█▎        | 96/714 [00:27<02:55,  3.52it/s] 14%|█▎        | 97/714 [00:27<02:51,  3.60it/s] 14%|█▎        | 98/714 [00:27<02:50,  3.61it/s] 14%|█▍        | 99/714 [00:27<02:53,  3.54it/s] 14%|█▍        | 100/714 [00:28<02:56,  3.49it/s] 14%|█▍        | 101/714 [00:28<02:55,  3.49it/s] 14%|█▍        | 102/714 [00:28<02:51,  3.57it/s] 14%|█▍        | 103/714 [00:29<02:48,  3.63it/s] 15%|█▍        | 104/714 [00:29<02:49,  3.59it/s] 15%|█▍        | 105/714 [00:29<02:53,  3.52it/s] 15%|█▍        | 106/714 [00:29<02:57,  3.42it/s] 15%|█▍        | 107/714 [00:30<02:57,  3.41it/s] 15%|█▌        | 108/714 [00:30<02:54,  3.46it/s] 15%|█▌        | 109/714 [00:30<02:50,  3.54it/s] 15%|█▌        | 110/714 [00:31<02:51,  3.53it/s] 16%|█▌        | 111/714 [00:31<02:53,  3.48it/s] 16%|█▌        | 112/714 [00:31<02:58,  3.37it/s] 16%|█▌        | 113/714 [00:32<02:58,  3.38it/s] 16%|█▌        | 114/714 [00:32<02:50,  3.51it/s] 16%|█▌        | 115/714 [00:32<02:47,  3.58it/s] 16%|█▌        | 116/714 [00:32<02:48,  3.55it/s] 16%|█▋        | 117/714 [00:33<02:48,  3.54it/s] 17%|█▋        | 118/714 [00:33<02:45,  3.61it/s] 17%|█▋        | 119/714 [00:33<02:43,  3.64it/s] 17%|█▋        | 120/714 [00:33<02:46,  3.57it/s] 17%|█▋        | 121/714 [00:34<02:51,  3.46it/s] 17%|█▋        | 122/714 [00:34<02:55,  3.38it/s] 17%|█▋        | 123/714 [00:34<02:52,  3.43it/s] 17%|█▋        | 124/714 [00:35<02:47,  3.53it/s] 18%|█▊        | 125/714 [00:35<02:45,  3.56it/s] 18%|█▊        | 126/714 [00:35<02:43,  3.61it/s] 18%|█▊        | 127/714 [00:35<02:41,  3.64it/s] 18%|█▊        | 128/714 [00:36<02:35,  3.76it/s] 18%|█▊        | 129/714 [00:36<02:33,  3.81it/s] 18%|█▊        | 130/714 [00:36<02:31,  3.86it/s] 18%|█▊        | 131/714 [00:36<02:36,  3.73it/s] 18%|█▊        | 132/714 [00:37<02:40,  3.63it/s] 19%|█▊        | 133/714 [00:37<02:41,  3.61it/s] 19%|█▉        | 134/714 [00:37<02:39,  3.64it/s] 19%|█▉        | 135/714 [00:38<02:42,  3.57it/s] 19%|█▉        | 136/714 [00:38<02:41,  3.59it/s] 19%|█▉        | 137/714 [00:38<02:37,  3.66it/s] 19%|█▉        | 138/714 [00:38<02:40,  3.59it/s] 19%|█▉        | 139/714 [00:39<02:44,  3.50it/s] 20%|█▉        | 140/714 [00:39<02:39,  3.59it/s] 20%|█▉        | 141/714 [00:39<02:41,  3.55it/s] 20%|█▉        | 142/714 [00:40<02:47,  3.42it/s] 20%|██        | 143/714 [00:40<02:48,  3.40it/s] 20%|██        | 144/714 [00:40<02:45,  3.45it/s] 20%|██        | 145/714 [00:40<02:41,  3.51it/s] 20%|██        | 146/714 [00:41<02:48,  3.37it/s] 21%|██        | 147/714 [00:41<02:49,  3.35it/s] 21%|██        | 148/714 [00:41<02:47,  3.38it/s] 21%|██        | 149/714 [00:42<02:49,  3.34it/s] 21%|██        | 150/714 [00:42<02:48,  3.35it/s] 21%|██        | 151/714 [00:42<02:44,  3.42it/s] 21%|██▏       | 152/714 [00:43<02:45,  3.40it/s] 21%|██▏       | 153/714 [00:43<02:50,  3.30it/s] 22%|██▏       | 154/714 [00:43<02:48,  3.33it/s] 22%|██▏       | 155/714 [00:43<02:44,  3.41it/s] 22%|██▏       | 156/714 [00:44<02:43,  3.42it/s] 22%|██▏       | 157/714 [00:44<02:45,  3.36it/s] 22%|██▏       | 158/714 [00:44<02:50,  3.27it/s] 22%|██▏       | 159/714 [00:45<02:45,  3.35it/s] 22%|██▏       | 160/714 [00:45<02:43,  3.39it/s] 23%|██▎       | 161/714 [00:45<02:44,  3.36it/s] 23%|██▎       | 162/714 [00:46<02:43,  3.39it/s] 23%|██▎       | 163/714 [00:46<02:43,  3.38it/s] 23%|██▎       | 164/714 [00:46<02:46,  3.31it/s] 23%|██▎       | 165/714 [00:46<02:46,  3.29it/s] 23%|██▎       | 166/714 [00:47<02:45,  3.31it/s] 23%|██▎       | 167/714 [00:47<02:49,  3.22it/s] 24%|██▎       | 168/714 [00:47<02:49,  3.21it/s] 24%|██▎       | 169/714 [00:48<02:52,  3.16it/s] 24%|██▍       | 170/714 [00:48<02:46,  3.26it/s] 24%|██▍       | 171/714 [00:48<02:43,  3.33it/s] 24%|██▍       | 172/714 [00:49<02:40,  3.38it/s] 24%|██▍       | 173/714 [00:49<02:43,  3.32it/s] 24%|██▍       | 174/714 [00:49<02:50,  3.17it/s] 25%|██▍       | 175/714 [00:50<02:49,  3.18it/s] 25%|██▍       | 176/714 [00:50<02:47,  3.21it/s] 25%|██▍       | 177/714 [00:50<02:46,  3.22it/s] 25%|██▍       | 178/714 [00:50<02:42,  3.30it/s] 25%|██▌       | 179/714 [00:51<02:42,  3.28it/s] 25%|██▌       | 180/714 [00:51<02:45,  3.23it/s] 25%|██▌       | 181/714 [00:51<02:42,  3.28it/s] 25%|██▌       | 182/714 [00:52<02:45,  3.22it/s] 26%|██▌       | 183/714 [00:52<02:48,  3.14it/s] 26%|██▌       | 184/714 [00:52<02:45,  3.19it/s] 26%|██▌       | 185/714 [00:53<02:49,  3.13it/s] 26%|██▌       | 186/714 [00:53<02:51,  3.08it/s] 26%|██▌       | 187/714 [00:53<02:53,  3.03it/s] 26%|██▋       | 188/714 [00:54<02:52,  3.05it/s] 26%|██▋       | 189/714 [00:54<02:57,  2.96it/s] 27%|██▋       | 190/714 [00:54<03:02,  2.87it/s] 27%|██▋       | 191/714 [00:55<03:06,  2.80it/s] 27%|██▋       | 192/714 [00:55<03:03,  2.85it/s] 27%|██▋       | 193/714 [00:55<03:02,  2.85it/s] 27%|██▋       | 194/714 [00:56<02:59,  2.90it/s] 27%|██▋       | 195/714 [00:56<03:00,  2.88it/s] 27%|██▋       | 196/714 [00:56<02:57,  2.92it/s] 28%|██▊       | 197/714 [00:57<03:00,  2.86it/s] 28%|██▊       | 198/714 [00:57<03:03,  2.81it/s] 28%|██▊       | 199/714 [00:58<03:03,  2.81it/s] 28%|██▊       | 200/714 [00:58<02:58,  2.88it/s] 28%|██▊       | 201/714 [00:58<02:59,  2.85it/s] 28%|██▊       | 202/714 [00:59<02:59,  2.85it/s] 28%|██▊       | 203/714 [00:59<03:05,  2.75it/s] 29%|██▊       | 204/714 [00:59<03:07,  2.72it/s] 29%|██▊       | 205/714 [01:00<03:10,  2.67it/s] 29%|██▉       | 206/714 [01:00<03:10,  2.67it/s] 29%|██▉       | 207/714 [01:01<03:09,  2.68it/s] 29%|██▉       | 208/714 [01:01<03:02,  2.77it/s] 29%|██▉       | 209/714 [01:01<03:02,  2.77it/s] 29%|██▉       | 210/714 [01:02<02:59,  2.80it/s] 30%|██▉       | 211/714 [01:02<03:07,  2.68it/s] 30%|██▉       | 212/714 [01:02<03:08,  2.67it/s] 30%|██▉       | 213/714 [01:03<03:01,  2.76it/s] 30%|██▉       | 214/714 [01:03<03:01,  2.76it/s] 30%|███       | 215/714 [01:03<03:04,  2.70it/s] 30%|███       | 216/714 [01:04<03:03,  2.71it/s] 30%|███       | 217/714 [01:04<02:58,  2.79it/s] 31%|███       | 218/714 [01:04<02:53,  2.85it/s] 31%|███       | 219/714 [01:05<02:52,  2.87it/s] 31%|███       | 220/714 [01:05<02:56,  2.79it/s] 31%|███       | 221/714 [01:06<02:53,  2.84it/s] 31%|███       | 222/714 [01:06<02:50,  2.89it/s] 31%|███       | 223/714 [01:06<02:51,  2.87it/s] 31%|███▏      | 224/714 [01:07<02:54,  2.81it/s] 32%|███▏      | 225/714 [01:07<02:51,  2.85it/s] 32%|███▏      | 226/714 [01:07<02:48,  2.89it/s] 32%|███▏      | 227/714 [01:08<02:46,  2.93it/s] 32%|███▏      | 228/714 [01:08<02:48,  2.88it/s] 32%|███▏      | 229/714 [01:08<02:51,  2.83it/s] 32%|███▏      | 230/714 [01:09<02:48,  2.88it/s] 32%|███▏      | 231/714 [01:09<02:46,  2.90it/s] 32%|███▏      | 232/714 [01:09<02:46,  2.89it/s] 33%|███▎      | 233/714 [01:10<02:54,  2.75it/s] 33%|███▎      | 234/714 [01:10<03:03,  2.62it/s] 33%|███▎      | 235/714 [01:11<03:07,  2.55it/s] 33%|███▎      | 236/714 [01:11<03:05,  2.58it/s] 33%|███▎      | 237/714 [01:11<03:04,  2.59it/s] 33%|███▎      | 238/714 [01:12<03:09,  2.52it/s] 33%|███▎      | 239/714 [01:12<03:06,  2.55it/s] 34%|███▎      | 240/714 [01:13<03:06,  2.55it/s] 34%|███▍      | 241/714 [01:13<02:59,  2.63it/s] 34%|███▍      | 242/714 [01:13<02:58,  2.64it/s] 34%|███▍      | 243/714 [01:14<03:01,  2.59it/s] 34%|███▍      | 244/714 [01:14<02:58,  2.64it/s] 34%|███▍      | 245/714 [01:14<02:48,  2.78it/s] 34%|███▍      | 246/714 [01:15<02:47,  2.80it/s] 35%|███▍      | 247/714 [01:15<02:54,  2.68it/s] 35%|███▍      | 248/714 [01:16<03:01,  2.56it/s] 35%|███▍      | 249/714 [01:16<03:04,  2.51it/s] 35%|███▌      | 250/714 [01:16<03:03,  2.52it/s] 35%|███▌      | 251/714 [01:17<03:11,  2.42it/s] 35%|███▌      | 252/714 [01:17<03:15,  2.36it/s] 35%|███▌      | 253/714 [01:18<03:17,  2.34it/s] 36%|███▌      | 254/714 [01:18<03:13,  2.38it/s] 36%|███▌      | 255/714 [01:18<03:10,  2.41it/s] 36%|███▌      | 256/714 [01:19<03:04,  2.48it/s] 36%|███▌      | 257/714 [01:19<03:10,  2.40it/s] 36%|███▌      | 258/714 [01:20<03:09,  2.40it/s] 36%|███▋      | 259/714 [01:20<03:01,  2.51it/s] 36%|███▋      | 260/714 [01:20<02:55,  2.59it/s] 37%|███▋      | 261/714 [01:21<02:49,  2.67it/s] 37%|███▋      | 262/714 [01:21<02:49,  2.67it/s] 37%|███▋      | 263/714 [01:22<02:50,  2.64it/s] 37%|███▋      | 264/714 [01:22<02:50,  2.64it/s] 37%|███▋      | 265/714 [01:22<02:51,  2.63it/s] 37%|███▋      | 266/714 [01:23<02:45,  2.70it/s] 37%|███▋      | 267/714 [01:23<02:43,  2.74it/s] 38%|███▊      | 268/714 [01:23<02:43,  2.73it/s] 38%|███▊      | 269/714 [01:24<02:49,  2.62it/s] 38%|███▊      | 270/714 [01:24<02:54,  2.55it/s] 38%|███▊      | 271/714 [01:25<02:54,  2.54it/s] 38%|███▊      | 272/714 [01:25<02:47,  2.65it/s] 38%|███▊      | 273/714 [01:25<02:43,  2.69it/s] 38%|███▊      | 274/714 [01:26<02:44,  2.67it/s] 39%|███▊      | 275/714 [01:26<02:52,  2.54it/s] 39%|███▊      | 276/714 [01:27<02:52,  2.54it/s] 39%|███▉      | 277/714 [01:27<02:53,  2.51it/s] 39%|███▉      | 278/714 [01:27<02:53,  2.51it/s] 39%|███▉      | 279/714 [01:28<03:01,  2.40it/s] 39%|███▉      | 280/714 [01:28<03:03,  2.37it/s] 39%|███▉      | 281/714 [01:29<03:09,  2.29it/s] 39%|███▉      | 282/714 [01:29<03:11,  2.26it/s] 40%|███▉      | 283/714 [01:30<03:12,  2.24it/s] 40%|███▉      | 284/714 [01:30<03:08,  2.29it/s] 40%|███▉      | 285/714 [01:30<02:58,  2.40it/s] 40%|████      | 286/714 [01:31<02:52,  2.48it/s] 40%|████      | 287/714 [01:31<02:50,  2.50it/s] 40%|████      | 288/714 [01:32<02:52,  2.47it/s] 40%|████      | 289/714 [01:32<02:50,  2.49it/s] 41%|████      | 290/714 [01:32<02:53,  2.44it/s] 41%|████      | 291/714 [01:33<02:56,  2.40it/s] 41%|████      | 292/714 [01:33<02:59,  2.35it/s] 41%|████      | 293/714 [01:34<03:01,  2.32it/s] 41%|████      | 294/714 [01:34<02:52,  2.43it/s] 41%|████▏     | 295/714 [01:34<02:51,  2.45it/s] 41%|████▏     | 296/714 [01:35<02:54,  2.40it/s] 42%|████▏     | 297/714 [01:35<02:48,  2.47it/s] 42%|████▏     | 298/714 [01:36<02:52,  2.41it/s] 42%|████▏     | 299/714 [01:36<02:57,  2.34it/s] 42%|████▏     | 300/714 [01:37<02:58,  2.32it/s] 42%|████▏     | 301/714 [01:37<03:00,  2.29it/s] 42%|████▏     | 302/714 [01:38<03:00,  2.28it/s] 42%|████▏     | 303/714 [01:38<03:02,  2.25it/s] 43%|████▎     | 304/714 [01:38<03:06,  2.20it/s] 43%|████▎     | 305/714 [01:39<03:10,  2.15it/s] 43%|████▎     | 306/714 [01:39<03:06,  2.19it/s] 43%|████▎     | 307/714 [01:40<02:58,  2.29it/s] 43%|████▎     | 308/714 [01:40<02:55,  2.31it/s] 43%|████▎     | 309/714 [01:41<02:49,  2.39it/s] 43%|████▎     | 310/714 [01:41<02:52,  2.34it/s] 44%|████▎     | 311/714 [01:42<02:55,  2.30it/s] 44%|████▎     | 312/714 [01:42<02:53,  2.32it/s] 44%|████▍     | 313/714 [01:42<02:53,  2.31it/s] 44%|████▍     | 314/714 [01:43<02:51,  2.33it/s] 44%|████▍     | 315/714 [01:43<02:44,  2.43it/s] 44%|████▍     | 316/714 [01:44<02:40,  2.48it/s] 44%|████▍     | 317/714 [01:44<02:43,  2.43it/s] 45%|████▍     | 318/714 [01:44<02:44,  2.40it/s] 45%|████▍     | 319/714 [01:45<02:42,  2.44it/s] 45%|████▍     | 320/714 [01:45<02:33,  2.56it/s] 45%|████▍     | 321/714 [01:46<02:34,  2.55it/s] 45%|████▌     | 322/714 [01:46<02:40,  2.44it/s] 45%|████▌     | 323/714 [01:46<02:43,  2.39it/s] 45%|████▌     | 324/714 [01:47<02:43,  2.39it/s] 46%|████▌     | 325/714 [01:47<02:46,  2.34it/s] 46%|████▌     | 326/714 [01:48<02:42,  2.38it/s] 46%|████▌     | 327/714 [01:48<02:46,  2.33it/s] 46%|████▌     | 328/714 [01:49<02:48,  2.29it/s] 46%|████▌     | 329/714 [01:49<02:52,  2.23it/s] 46%|████▌     | 330/714 [01:50<02:55,  2.19it/s] 46%|████▋     | 331/714 [01:50<03:01,  2.11it/s] 46%|████▋     | 332/714 [01:50<02:55,  2.17it/s] 47%|████▋     | 333/714 [01:51<02:55,  2.17it/s] 47%|████▋     | 334/714 [01:51<02:58,  2.13it/s] 47%|████▋     | 335/714 [01:52<03:03,  2.06it/s] 47%|████▋     | 336/714 [01:52<03:03,  2.06it/s] 47%|████▋     | 337/714 [01:53<03:02,  2.06it/s] 47%|████▋     | 338/714 [01:53<03:05,  2.03it/s] 47%|████▋     | 339/714 [01:54<03:13,  1.94it/s] 48%|████▊     | 340/714 [01:55<03:26,  1.81it/s] 48%|████▊     | 341/714 [01:55<03:31,  1.76it/s] 48%|████▊     | 342/714 [01:56<03:26,  1.80it/s] 48%|████▊     | 343/714 [01:56<03:30,  1.76it/s] 48%|████▊     | 344/714 [01:57<03:37,  1.70it/s] 48%|████▊     | 345/714 [01:58<03:32,  1.74it/s] 48%|████▊     | 346/714 [01:58<03:28,  1.76it/s] 49%|████▊     | 347/714 [01:59<03:27,  1.77it/s] 49%|████▊     | 348/714 [01:59<03:32,  1.72it/s] 49%|████▉     | 349/714 [02:00<03:43,  1.63it/s] 49%|████▉     | 350/714 [02:01<03:51,  1.57it/s] 49%|████▉     | 351/714 [02:01<04:00,  1.51it/s] 49%|████▉     | 352/714 [02:02<04:12,  1.43it/s] 49%|████▉     | 353/714 [02:03<05:02,  1.19it/s] 50%|████▉     | 354/714 [02:04<04:49,  1.24it/s] 50%|████▉     | 355/714 [02:05<04:20,  1.38it/s] 50%|████▉     | 356/714 [02:05<04:19,  1.38it/s] 50%|█████     | 357/714 [02:06<05:01,  1.18it/s] 50%|█████     | 358/714 [02:07<05:12,  1.14it/s] 50%|█████     | 359/714 [02:08<04:31,  1.31it/s] 50%|█████     | 360/714 [02:09<04:17,  1.38it/s] 51%|█████     | 361/714 [02:10<04:42,  1.25it/s] 51%|█████     | 362/714 [02:11<05:15,  1.12it/s] 51%|█████     | 363/714 [02:11<04:45,  1.23it/s] 51%|█████     | 364/714 [02:13<05:41,  1.03it/s] 51%|█████     | 365/714 [02:13<05:32,  1.05it/s] 51%|█████▏    | 366/714 [02:14<04:53,  1.19it/s] 51%|█████▏    | 367/714 [02:15<05:08,  1.13it/s] 52%|█████▏    | 368/714 [02:16<06:01,  1.05s/it] 52%|█████▏    | 369/714 [02:17<05:20,  1.07it/s] 52%|█████▏    | 370/714 [02:18<05:39,  1.01it/s] 52%|█████▏    | 371/714 [02:20<06:23,  1.12s/it] 52%|█████▏    | 372/714 [02:20<05:36,  1.01it/s] 52%|█████▏    | 373/714 [02:22<06:19,  1.11s/it] 52%|█████▏    | 374/714 [02:23<05:58,  1.06s/it] 53%|█████▎    | 375/714 [02:23<05:15,  1.08it/s] 53%|█████▎    | 376/714 [02:25<06:16,  1.12s/it] 53%|█████▎    | 377/714 [02:26<07:02,  1.25s/it] 53%|█████▎    | 378/714 [02:27<06:25,  1.15s/it] 53%|█████▎    | 379/714 [02:29<06:49,  1.22s/it] 53%|█████▎    | 380/714 [02:30<07:11,  1.29s/it] 53%|█████▎    | 381/714 [02:31<06:14,  1.13s/it] 54%|█████▎    | 382/714 [02:32<06:27,  1.17s/it] 54%|█████▎    | 383/714 [02:34<06:48,  1.23s/it] 54%|█████▍    | 384/714 [02:35<06:19,  1.15s/it] 54%|█████▍    | 385/714 [02:35<05:18,  1.03it/s] 54%|█████▍    | 386/714 [02:37<06:48,  1.25s/it] 54%|█████▍    | 387/714 [02:39<07:20,  1.35s/it] 54%|█████▍    | 388/714 [02:40<06:37,  1.22s/it] 54%|█████▍    | 389/714 [02:41<06:25,  1.19s/it] 55%|█████▍    | 390/714 [02:42<07:02,  1.30s/it] 55%|█████▍    | 391/714 [02:44<07:23,  1.37s/it] 55%|█████▍    | 392/714 [02:45<07:46,  1.45s/it] 55%|█████▌    | 393/714 [02:47<07:17,  1.36s/it] 55%|█████▌    | 394/714 [02:47<06:08,  1.15s/it] 55%|█████▌    | 395/714 [02:48<05:47,  1.09s/it] 55%|█████▌    | 396/714 [02:50<06:17,  1.19s/it] 56%|█████▌    | 397/714 [02:51<06:36,  1.25s/it] 56%|█████▌    | 398/714 [02:52<06:57,  1.32s/it] 56%|█████▌    | 399/714 [02:54<07:06,  1.35s/it] 56%|█████▌    | 400/714 [02:55<07:04,  1.35s/it] 56%|█████▌    | 401/714 [02:56<06:13,  1.19s/it] 56%|█████▋    | 402/714 [02:57<05:34,  1.07s/it] 56%|█████▋    | 403/714 [02:59<06:34,  1.27s/it] 57%|█████▋    | 404/714 [03:00<06:42,  1.30s/it] 57%|█████▋    | 405/714 [03:01<06:52,  1.34s/it] 57%|█████▋    | 406/714 [03:03<06:38,  1.29s/it] 57%|█████▋    | 407/714 [03:03<05:45,  1.13s/it] 57%|█████▋    | 408/714 [03:05<07:12,  1.41s/it] 57%|█████▋    | 409/714 [03:07<07:18,  1.44s/it] 57%|█████▋    | 410/714 [03:08<07:18,  1.44s/it] 58%|█████▊    | 411/714 [03:10<07:18,  1.45s/it] 58%|█████▊    | 412/714 [03:11<07:28,  1.48s/it] 58%|█████▊    | 413/714 [03:13<07:26,  1.48s/it] 58%|█████▊    | 414/714 [03:14<07:20,  1.47s/it] 58%|█████▊    | 415/714 [03:16<07:13,  1.45s/it] 58%|█████▊    | 416/714 [03:17<07:06,  1.43s/it] 58%|█████▊    | 417/714 [03:18<05:53,  1.19s/it] 59%|█████▊    | 418/714 [03:19<05:41,  1.15s/it] 59%|█████▊    | 419/714 [03:20<05:56,  1.21s/it] 59%|█████▉    | 420/714 [03:21<06:07,  1.25s/it] 59%|█████▉    | 421/714 [03:23<06:13,  1.27s/it] 59%|█████▉    | 422/714 [03:24<06:21,  1.31s/it] 59%|█████▉    | 423/714 [03:26<06:29,  1.34s/it] 59%|█████▉    | 424/714 [03:27<06:36,  1.37s/it] 60%|█████▉    | 425/714 [03:29<06:53,  1.43s/it] 60%|█████▉    | 426/714 [03:30<06:52,  1.43s/it] 60%|█████▉    | 427/714 [03:31<06:47,  1.42s/it] 60%|█████▉    | 428/714 [03:33<06:52,  1.44s/it] 60%|██████    | 429/714 [03:34<06:48,  1.43s/it] 60%|██████    | 430/714 [03:36<06:42,  1.42s/it] 60%|██████    | 431/714 [03:37<06:43,  1.43s/it] 61%|██████    | 432/714 [03:39<06:40,  1.42s/it] 61%|██████    | 433/714 [03:40<06:45,  1.44s/it] 61%|██████    | 434/714 [03:41<06:46,  1.45s/it] 61%|██████    | 435/714 [03:43<06:41,  1.44s/it] 61%|██████    | 436/714 [03:44<06:34,  1.42s/it] 61%|██████    | 437/714 [03:46<06:38,  1.44s/it] 61%|██████▏   | 438/714 [03:47<06:38,  1.44s/it] 61%|██████▏   | 439/714 [03:49<06:29,  1.41s/it] 62%|██████▏   | 440/714 [03:50<06:24,  1.40s/it] 62%|██████▏   | 441/714 [03:51<06:17,  1.38s/it] 62%|██████▏   | 442/714 [03:52<05:55,  1.31s/it] 62%|██████▏   | 443/714 [03:53<05:00,  1.11s/it] 62%|██████▏   | 444/714 [03:55<05:32,  1.23s/it] 62%|██████▏   | 445/714 [03:56<05:50,  1.30s/it] 62%|██████▏   | 446/714 [03:57<05:53,  1.32s/it] 63%|██████▎   | 447/714 [03:59<05:58,  1.34s/it] 63%|██████▎   | 448/714 [04:00<06:11,  1.40s/it] 63%|██████▎   | 449/714 [04:02<06:28,  1.47s/it] 63%|██████▎   | 450/714 [04:04<06:40,  1.52s/it] 63%|██████▎   | 451/714 [04:05<06:39,  1.52s/it] 63%|██████▎   | 452/714 [04:07<06:33,  1.50s/it] 63%|██████▎   | 453/714 [04:08<06:42,  1.54s/it] 64%|██████▎   | 454/714 [04:10<06:38,  1.53s/it] 64%|██████▎   | 455/714 [04:11<06:21,  1.47s/it] 64%|██████▍   | 456/714 [04:12<06:18,  1.47s/it] 64%|██████▍   | 457/714 [04:14<06:25,  1.50s/it] 64%|██████▍   | 458/714 [04:16<06:21,  1.49s/it] 64%|██████▍   | 459/714 [04:17<06:24,  1.51s/it] 64%|██████▍   | 460/714 [04:19<06:24,  1.52s/it] 65%|██████▍   | 461/714 [04:20<06:15,  1.48s/it] 65%|██████▍   | 462/714 [04:21<06:10,  1.47s/it] 65%|██████▍   | 463/714 [04:23<06:03,  1.45s/it] 65%|██████▍   | 464/714 [04:24<06:01,  1.45s/it] 65%|██████▌   | 465/714 [04:26<05:51,  1.41s/it] 65%|██████▌   | 466/714 [04:27<05:45,  1.39s/it] 65%|██████▌   | 467/714 [04:28<05:44,  1.39s/it] 66%|██████▌   | 468/714 [04:30<05:52,  1.43s/it] 66%|██████▌   | 469/714 [04:32<06:05,  1.49s/it] 66%|██████▌   | 470/714 [04:33<06:14,  1.53s/it] 66%|██████▌   | 471/714 [04:35<06:15,  1.55s/it] 66%|██████▌   | 472/714 [04:36<06:09,  1.53s/it] 66%|██████▌   | 473/714 [04:38<06:00,  1.49s/it] 66%|██████▋   | 474/714 [04:39<05:49,  1.46s/it] 67%|██████▋   | 475/714 [04:40<05:49,  1.46s/it] 67%|██████▋   | 476/714 [04:42<05:45,  1.45s/it] 67%|██████▋   | 477/714 [04:43<05:35,  1.42s/it] 67%|██████▋   | 478/714 [04:45<05:32,  1.41s/it] 67%|██████▋   | 479/714 [04:46<05:41,  1.45s/it] 67%|██████▋   | 480/714 [04:48<05:48,  1.49s/it] 67%|██████▋   | 481/714 [04:49<05:46,  1.49s/it] 68%|██████▊   | 482/714 [04:51<05:46,  1.49s/it] 68%|██████▊   | 483/714 [04:52<05:45,  1.50s/it] 68%|██████▊   | 484/714 [04:54<05:47,  1.51s/it] 68%|██████▊   | 485/714 [04:55<05:46,  1.52s/it] 68%|██████▊   | 486/714 [04:57<05:32,  1.46s/it] 68%|██████▊   | 487/714 [04:58<05:26,  1.44s/it] 68%|██████▊   | 488/714 [05:00<05:31,  1.47s/it] 68%|██████▊   | 489/714 [05:01<05:33,  1.48s/it] 69%|██████▊   | 490/714 [05:03<05:28,  1.47s/it] 69%|██████▉   | 491/714 [05:04<05:30,  1.48s/it] 69%|██████▉   | 492/714 [05:05<05:18,  1.44s/it] 69%|██████▉   | 493/714 [05:07<05:10,  1.40s/it] 69%|██████▉   | 494/714 [05:08<05:03,  1.38s/it] 69%|██████▉   | 495/714 [05:09<04:59,  1.37s/it] 69%|██████▉   | 496/714 [05:11<05:02,  1.39s/it] 70%|██████▉   | 497/714 [05:12<05:13,  1.44s/it] 70%|██████▉   | 498/714 [05:14<05:13,  1.45s/it] 70%|██████▉   | 499/714 [05:15<05:09,  1.44s/it] 70%|███████   | 500/714 [05:17<05:05,  1.43s/it] 70%|███████   | 501/714 [05:18<05:08,  1.45s/it] 70%|███████   | 502/714 [05:20<05:09,  1.46s/it] 70%|███████   | 503/714 [05:21<05:13,  1.49s/it] 71%|███████   | 504/714 [05:23<05:20,  1.53s/it] 71%|███████   | 505/714 [05:24<05:25,  1.56s/it] 71%|███████   | 506/714 [05:26<05:22,  1.55s/it] 71%|███████   | 507/714 [05:27<05:08,  1.49s/it] 71%|███████   | 508/714 [05:29<05:02,  1.47s/it] 71%|███████▏  | 509/714 [05:30<05:03,  1.48s/it] 71%|███████▏  | 510/714 [05:32<05:01,  1.48s/it] 72%|███████▏  | 511/714 [05:33<05:03,  1.50s/it] 72%|███████▏  | 512/714 [05:35<05:04,  1.51s/it] 72%|███████▏  | 513/714 [05:36<04:53,  1.46s/it] 72%|███████▏  | 514/714 [05:37<04:44,  1.42s/it] 72%|███████▏  | 515/714 [05:39<04:40,  1.41s/it] 72%|███████▏  | 516/714 [05:40<04:36,  1.40s/it] 72%|███████▏  | 517/714 [05:42<04:32,  1.38s/it] 73%|███████▎  | 518/714 [05:43<04:45,  1.46s/it] 73%|███████▎  | 519/714 [05:45<04:54,  1.51s/it] 73%|███████▎  | 520/714 [05:46<04:55,  1.53s/it] 73%|███████▎  | 521/714 [05:48<04:51,  1.51s/it] 73%|███████▎  | 522/714 [05:49<04:45,  1.49s/it] 73%|███████▎  | 523/714 [05:51<04:38,  1.46s/it] 73%|███████▎  | 524/714 [05:52<04:38,  1.47s/it] 74%|███████▎  | 525/714 [05:54<04:35,  1.46s/it] 74%|███████▎  | 526/714 [05:55<04:26,  1.42s/it] 74%|███████▍  | 527/714 [05:56<04:18,  1.38s/it] 74%|███████▍  | 528/714 [05:58<04:19,  1.40s/it] 74%|███████▍  | 529/714 [05:59<04:25,  1.43s/it] 74%|███████▍  | 530/714 [06:01<04:24,  1.44s/it] 74%|███████▍  | 531/714 [06:02<04:33,  1.50s/it] 75%|███████▍  | 532/714 [06:04<05:06,  1.68s/it] 75%|███████▍  | 533/714 [06:07<05:57,  1.97s/it] 75%|███████▍  | 534/714 [06:09<05:55,  1.98s/it] 75%|███████▍  | 535/714 [06:10<05:22,  1.80s/it] 75%|███████▌  | 536/714 [06:12<05:04,  1.71s/it] 75%|███████▌  | 537/714 [06:13<04:52,  1.65s/it] 75%|███████▌  | 538/714 [06:15<04:39,  1.59s/it] 75%|███████▌  | 539/714 [06:16<04:27,  1.53s/it] 76%|███████▌  | 540/714 [06:18<04:21,  1.50s/it] 76%|███████▌  | 541/714 [06:19<04:10,  1.45s/it] 76%|███████▌  | 542/714 [06:20<04:05,  1.43s/it] 76%|███████▌  | 543/714 [06:22<04:07,  1.45s/it] 76%|███████▌  | 544/714 [06:23<04:05,  1.45s/it] 76%|███████▋  | 545/714 [06:25<03:58,  1.41s/it] 76%|███████▋  | 546/714 [06:26<03:57,  1.42s/it] 77%|███████▋  | 547/714 [06:28<04:01,  1.45s/it] 77%|███████▋  | 548/714 [06:29<03:53,  1.40s/it] 77%|███████▋  | 549/714 [06:30<03:50,  1.40s/it] 77%|███████▋  | 550/714 [06:32<03:57,  1.45s/it] 77%|███████▋  | 551/714 [06:33<04:02,  1.49s/it] 77%|███████▋  | 552/714 [06:36<04:56,  1.83s/it] 77%|███████▋  | 553/714 [06:39<05:25,  2.02s/it] 78%|███████▊  | 554/714 [06:41<05:52,  2.20s/it] 78%|███████▊  | 555/714 [06:43<05:16,  1.99s/it] 78%|███████▊  | 556/714 [06:44<04:52,  1.85s/it] 78%|███████▊  | 557/714 [06:46<04:38,  1.77s/it] 78%|███████▊  | 558/714 [06:47<04:20,  1.67s/it] 78%|███████▊  | 559/714 [06:49<04:03,  1.57s/it] 78%|███████▊  | 560/714 [06:50<03:51,  1.50s/it] 79%|███████▊  | 561/714 [06:51<03:41,  1.45s/it] 79%|███████▊  | 562/714 [06:53<03:37,  1.43s/it] 79%|███████▉  | 563/714 [06:54<03:38,  1.45s/it] 79%|███████▉  | 564/714 [06:56<03:40,  1.47s/it] 79%|███████▉  | 565/714 [06:57<03:46,  1.52s/it] 79%|███████▉  | 566/714 [06:59<03:47,  1.53s/it] 79%|███████▉  | 567/714 [07:00<03:45,  1.54s/it] 80%|███████▉  | 568/714 [07:03<04:35,  1.88s/it] 80%|███████▉  | 569/714 [07:06<05:09,  2.14s/it] 80%|███████▉  | 570/714 [07:08<04:59,  2.08s/it] 80%|███████▉  | 571/714 [07:09<04:29,  1.88s/it] 80%|████████  | 572/714 [07:11<04:08,  1.75s/it] 80%|████████  | 573/714 [07:12<03:57,  1.69s/it] 80%|████████  | 574/714 [07:14<03:43,  1.60s/it] 81%|████████  | 575/714 [07:15<03:34,  1.54s/it] 81%|████████  | 576/714 [07:16<03:28,  1.51s/it] 81%|████████  | 577/714 [07:18<03:29,  1.53s/it] 81%|████████  | 578/714 [07:19<03:21,  1.48s/it] 81%|████████  | 579/714 [07:21<03:12,  1.42s/it] 81%|████████  | 580/714 [07:22<03:12,  1.44s/it] 81%|████████▏ | 581/714 [07:24<03:14,  1.46s/it] 82%|████████▏ | 582/714 [07:25<03:15,  1.48s/it] 82%|████████▏ | 583/714 [07:27<03:10,  1.46s/it] 82%|████████▏ | 584/714 [07:28<03:07,  1.44s/it] 82%|████████▏ | 585/714 [07:29<03:02,  1.42s/it] 82%|████████▏ | 586/714 [07:31<03:03,  1.44s/it] 82%|████████▏ | 587/714 [07:33<03:45,  1.77s/it] 82%|████████▏ | 588/714 [07:36<04:21,  2.07s/it] 82%|████████▏ | 589/714 [07:38<04:30,  2.17s/it] 83%|████████▎ | 590/714 [07:40<04:07,  1.99s/it] 83%|████████▎ | 591/714 [07:41<03:44,  1.82s/it] 83%|████████▎ | 592/714 [07:42<02:56,  1.45s/it] 83%|████████▎ | 593/714 [07:43<02:25,  1.20s/it] 83%|████████▎ | 594/714 [07:44<02:18,  1.15s/it] 83%|████████▎ | 595/714 [07:45<02:20,  1.18s/it] 83%|████████▎ | 596/714 [07:46<01:55,  1.02it/s] 84%|████████▎ | 597/714 [07:46<01:38,  1.18it/s] 84%|████████▍ | 598/714 [07:47<01:31,  1.27it/s] 84%|████████▍ | 599/714 [07:47<01:28,  1.30it/s] 84%|████████▍ | 600/714 [07:48<01:22,  1.38it/s] 84%|████████▍ | 601/714 [07:49<01:20,  1.41it/s] 84%|████████▍ | 602/714 [07:49<01:22,  1.36it/s] 84%|████████▍ | 603/714 [07:50<01:20,  1.37it/s] 85%|████████▍ | 604/714 [07:51<01:20,  1.37it/s] 85%|████████▍ | 605/714 [07:52<01:22,  1.33it/s] 85%|████████▍ | 606/714 [07:53<01:22,  1.31it/s] 85%|████████▌ | 607/714 [07:53<01:21,  1.32it/s] 85%|████████▌ | 608/714 [07:54<01:15,  1.40it/s] 85%|████████▌ | 609/714 [07:54<01:10,  1.48it/s] 85%|████████▌ | 610/714 [07:55<01:10,  1.47it/s] 86%|████████▌ | 611/714 [07:56<01:09,  1.48it/s] 86%|████████▌ | 612/714 [07:56<01:06,  1.53it/s] 86%|████████▌ | 613/714 [07:57<01:07,  1.51it/s] 86%|████████▌ | 614/714 [07:58<01:06,  1.50it/s] 86%|████████▌ | 615/714 [07:58<01:04,  1.53it/s] 86%|████████▋ | 616/714 [07:59<01:01,  1.60it/s] 86%|████████▋ | 617/714 [08:00<00:58,  1.66it/s] 87%|████████▋ | 618/714 [08:00<00:58,  1.64it/s] 87%|████████▋ | 619/714 [08:01<00:57,  1.67it/s] 87%|████████▋ | 620/714 [08:01<00:55,  1.68it/s] 87%|████████▋ | 621/714 [08:02<00:55,  1.69it/s] 87%|████████▋ | 622/714 [08:03<00:55,  1.67it/s] 87%|████████▋ | 623/714 [08:03<00:52,  1.72it/s] 87%|████████▋ | 624/714 [08:04<00:49,  1.82it/s] 88%|████████▊ | 625/714 [08:04<00:47,  1.86it/s] 88%|████████▊ | 626/714 [08:05<00:46,  1.90it/s] 88%|████████▊ | 627/714 [08:05<00:44,  1.95it/s] 88%|████████▊ | 628/714 [08:06<00:44,  1.95it/s] 88%|████████▊ | 629/714 [08:06<00:44,  1.90it/s] 88%|████████▊ | 630/714 [08:07<00:43,  1.92it/s] 88%|████████▊ | 631/714 [08:07<00:44,  1.88it/s] 89%|████████▊ | 632/714 [08:08<00:46,  1.78it/s] 89%|████████▊ | 633/714 [08:08<00:46,  1.73it/s] 89%|████████▉ | 634/714 [08:09<00:44,  1.79it/s] 89%|████████▉ | 635/714 [08:09<00:41,  1.88it/s] 89%|████████▉ | 636/714 [08:10<00:39,  1.96it/s] 89%|████████▉ | 637/714 [08:10<00:38,  2.00it/s] 89%|████████▉ | 638/714 [08:11<00:37,  2.02it/s] 89%|████████▉ | 639/714 [08:11<00:37,  1.99it/s] 90%|████████▉ | 640/714 [08:12<00:38,  1.91it/s] 90%|████████▉ | 641/714 [08:12<00:38,  1.91it/s] 90%|████████▉ | 642/714 [08:13<00:37,  1.93it/s] 90%|█████████ | 643/714 [08:13<00:37,  1.91it/s] 90%|█████████ | 644/714 [08:14<00:35,  1.97it/s] 90%|█████████ | 645/714 [08:14<00:35,  1.97it/s] 90%|█████████ | 646/714 [08:15<00:35,  1.94it/s] 91%|█████████ | 647/714 [08:15<00:33,  2.00it/s] 91%|█████████ | 648/714 [08:16<00:33,  2.00it/s] 91%|█████████ | 649/714 [08:17<00:34,  1.91it/s] 91%|█████████ | 650/714 [08:17<00:34,  1.86it/s] 91%|█████████ | 651/714 [08:18<00:35,  1.79it/s] 91%|█████████▏| 652/714 [08:18<00:33,  1.83it/s] 91%|█████████▏| 653/714 [08:19<00:31,  1.94it/s] 92%|█████████▏| 654/714 [08:19<00:30,  1.94it/s] 92%|█████████▏| 655/714 [08:20<00:30,  1.95it/s] 92%|█████████▏| 656/714 [08:20<00:29,  1.94it/s] 92%|█████████▏| 657/714 [08:21<00:29,  1.93it/s] 92%|█████████▏| 658/714 [08:21<00:28,  1.94it/s] 92%|█████████▏| 659/714 [08:22<00:27,  1.97it/s] 92%|█████████▏| 660/714 [08:22<00:26,  2.05it/s] 93%|█████████▎| 661/714 [08:23<00:26,  2.04it/s] 93%|█████████▎| 662/714 [08:23<00:25,  2.00it/s] 93%|█████████▎| 663/714 [08:24<00:24,  2.07it/s] 93%|█████████▎| 664/714 [08:24<00:24,  2.06it/s] 93%|█████████▎| 665/714 [08:25<00:24,  1.99it/s] 93%|█████████▎| 666/714 [08:25<00:24,  1.97it/s] 93%|█████████▎| 667/714 [08:26<00:24,  1.93it/s] 94%|█████████▎| 668/714 [08:26<00:24,  1.91it/s] 94%|█████████▎| 669/714 [08:27<00:23,  1.90it/s] 94%|█████████▍| 670/714 [08:27<00:22,  1.92it/s] 94%|█████████▍| 671/714 [08:28<00:21,  1.98it/s] 94%|█████████▍| 672/714 [08:28<00:21,  1.97it/s] 94%|█████████▍| 673/714 [08:29<00:20,  1.96it/s] 94%|█████████▍| 674/714 [08:29<00:20,  1.96it/s] 95%|█████████▍| 675/714 [08:30<00:19,  1.98it/s] 95%|█████████▍| 676/714 [08:30<00:18,  2.01it/s] 95%|█████████▍| 677/714 [08:31<00:18,  2.02it/s] 95%|█████████▍| 678/714 [08:31<00:17,  2.05it/s] 95%|█████████▌| 679/714 [08:32<00:17,  2.06it/s] 95%|█████████▌| 680/714 [08:32<00:16,  2.10it/s] 95%|█████████▌| 681/714 [08:33<00:16,  2.03it/s] 96%|█████████▌| 682/714 [08:33<00:15,  2.06it/s] 96%|█████████▌| 683/714 [08:34<00:15,  2.05it/s] 96%|█████████▌| 684/714 [08:34<00:14,  2.01it/s] 96%|█████████▌| 685/714 [08:35<00:15,  1.93it/s] 96%|█████████▌| 686/714 [08:35<00:14,  1.89it/s] 96%|█████████▌| 687/714 [08:36<00:14,  1.85it/s] 96%|█████████▋| 688/714 [08:36<00:13,  1.88it/s] 96%|█████████▋| 689/714 [08:37<00:12,  1.95it/s] 97%|█████████▋| 690/714 [08:37<00:12,  1.96it/s] 97%|█████████▋| 691/714 [08:38<00:11,  2.04it/s] 97%|█████████▋| 692/714 [08:38<00:10,  2.07it/s] 97%|█████████▋| 693/714 [08:39<00:10,  2.04it/s] 97%|█████████▋| 694/714 [08:39<00:10,  1.98it/s] 97%|█████████▋| 695/714 [08:40<00:09,  1.93it/s] 97%|█████████▋| 696/714 [08:40<00:09,  1.89it/s] 98%|█████████▊| 697/714 [08:41<00:09,  1.86it/s] 98%|█████████▊| 698/714 [08:42<00:08,  1.88it/s] 98%|█████████▊| 699/714 [08:42<00:07,  1.97it/s] 98%|█████████▊| 700/714 [08:42<00:06,  2.03it/s] 98%|█████████▊| 701/714 [08:43<00:06,  2.15it/s] 98%|█████████▊| 702/714 [08:43<00:05,  2.17it/s] 98%|█████████▊| 703/714 [08:44<00:05,  2.07it/s] 99%|█████████▊| 704/714 [08:44<00:04,  2.05it/s] 99%|█████████▊| 705/714 [08:45<00:04,  2.14it/s] 99%|█████████▉| 706/714 [08:45<00:03,  2.16it/s] 99%|█████████▉| 707/714 [08:46<00:03,  2.12it/s] 99%|█████████▉| 708/714 [08:46<00:02,  2.15it/s] 99%|█████████▉| 709/714 [08:47<00:02,  2.13it/s] 99%|█████████▉| 710/714 [08:47<00:01,  2.15it/s]100%|█████████▉| 711/714 [08:47<00:01,  2.19it/s]100%|█████████▉| 712/714 [08:48<00:00,  2.15it/s]100%|█████████▉| 713/714 [08:48<00:00,  2.13it/s]100%|██████████| 714/714 [08:49<00:00,  2.13it/s]100%|██████████| 714/714 [08:49<00:00,  1.35it/s]
Map:   0%|          | 0/714 [00:00<?, ? examples/s]Map:  38%|███▊      | 268/714 [00:00<00:00, 2635.97 examples/s]Map:  75%|███████▍  | 532/714 [00:00<00:00, 2629.38 examples/s]Map: 100%|██████████| 714/714 [00:00<00:00, 1837.43 examples/s]
***** eval metrics *****
  eval_loss               =     0.1256
  eval_runtime            = 0:08:49.81
  eval_samples            =        714
  eval_samples_per_second =      1.348
  eval_steps_per_second   =      1.348
  eval_tokens             =     750989
